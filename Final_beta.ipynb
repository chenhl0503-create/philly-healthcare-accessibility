{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed66f979-fa03-4083-93fb-fdb1756ee366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        let retries = 0;\n",
       "        const open = () => {\n",
       "          if (comm.active) {\n",
       "            comm.open();\n",
       "          } else if (retries > 3) {\n",
       "            console.warn('Comm target never activated')\n",
       "          } else {\n",
       "            retries += 1\n",
       "            setTimeout(open, 500)\n",
       "          }\n",
       "        }\n",
       "        if (comm.active) {\n",
       "          comm.open();\n",
       "        } else {\n",
       "          setTimeout(open, 500)\n",
       "        }\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        })\n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='61319b6b-01c5-4743-bc00-caa5d4a42924'>\n",
       "  <div id=\"fd7f56fa-24f6-48c8-b5fd-d1b54e9602be\" data-root-id=\"61319b6b-01c5-4743-bc00-caa5d4a42924\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ca5c239a-cbdf-4214-9ed2-04a1d5e42ef8\":{\"version\":\"3.8.0\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"f0b95b1c-cf12-4e9b-8dad-92bd163f5aa5\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"fb6281d6-94b1-47ef-8a8f-f8d13946d95b\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"61319b6b-01c5-4743-bc00-caa5d4a42924\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"9dc4838b-6253-41e3-9c11-4532275bdb8c\",\"attributes\":{\"plot_id\":\"61319b6b-01c5-4743-bc00-caa5d4a42924\",\"comm_id\":\"f57168cd19ad4f268a51098045c140fa\",\"client_comm_id\":\"ed03c62282f84ee989414140846b28f0\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"ca5c239a-cbdf-4214-9ed2-04a1d5e42ef8\",\"roots\":{\"61319b6b-01c5-4743-bc00-caa5d4a42924\":\"fd7f56fa-24f6-48c8-b5fd-d1b54e9602be\"},\"root_ids\":[\"61319b6b-01c5-4743-bc00-caa5d4a42924\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "61319b6b-01c5-4743-bc00-caa5d4a42924"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO, StringIO\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import mapclassify\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import warnings\n",
    "import networkx as nx\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842a737f-6b5d-4bf7-9b6d-b5b6b30876a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory of your project\n",
    "BASE_DIR = Path(\".\")\n",
    "\n",
    "# Census and geography constants\n",
    "PHILLY_STATE_FIPS = \"42\"\n",
    "PHILLY_COUNTY_FIPS = \"101\"\n",
    "# Data directories\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_RAW = DATA_DIR / \"raw\"\n",
    "DATA_PROCESSED = DATA_DIR / \"processed\"\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Headers to mimic a browser\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "G = ox.graph_from_place(\"Philadelphia, Pennsylvania, USA\", network_type='drive')\n",
    "ox.save_graph_shapefile(G, filepath=\"./Data/philadelphia_osm_roads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d19b1f-6948-4d5b-b3d3-fd5e58a2ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"02cfb7601cb4d601454bee8c28d14d90211b5baf\"\n",
    "url = (\"https://api.census.gov/data/2021/acs/acs5?get=B01003_001E\"\n",
    "       \"&for=block%20group:*&in=state:42%20county:101&key=\" + api_key)\n",
    "resp = requests.get(url)\n",
    "data = resp.json() \n",
    "columns, *rows = data\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.rename(columns={\"B01003_001E\": \"population\"}, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c7a663-6b4c-4b85-8993-d036c4cf369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_hospitals():\n",
    "    \"\"\"Fetches Philadelphia Hospitals from OpenDataPhilly (GeoJSON).\"\"\"\n",
    "    print(\" Fetching Philadelphia Hospitals...\")\n",
    "    # Updated: Using a direct stable resource URL found on OpenDataPhilly\n",
    "    url = \"https://opendata.arcgis.com/datasets/df8dc18412494e5abbb021e2f33057b2_0.geojson\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        if response.status_code == 200:\n",
    "            output_path = DATA_DIR / \"phl_hospitals.geojson\"\n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"    Saved hospitals to {output_path}\")\n",
    "        else:\n",
    "            print(f\"    API Error: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch hospitals: {e}\")\n",
    "\n",
    "def scrape_urgent_care_backup():\n",
    "    \"\"\"Backup: Scrapes address list if GeoJSON fails.\"\"\"\n",
    "    print(\"  (Backup) Scraping Health Centers from Web...\")\n",
    "    url = \"https://www.phila.gov/services/mental-physical-health/city-health-centers/\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        centers = []\n",
    "        tables = soup.find_all(\"table\")\n",
    "        \n",
    "        for table in tables:\n",
    "            rows = table.find_all(\"tr\")[1:]\n",
    "            for row in rows:\n",
    "                cols = row.find_all(\"td\")\n",
    "                if len(cols) >= 2:\n",
    "                    name = cols[0].get_text(strip=True)\n",
    "                    address = cols[1].get_text(strip=True).replace('\\n', ' ')\n",
    "                    centers.append({\"name\": name, \"address\": address, \"type\": \"City Health Center\"})\n",
    "        \n",
    "        if centers:\n",
    "            df = pd.DataFrame(centers)\n",
    "            csv_path = DATA_DIR / \"scraped_health_centers.csv\"\n",
    "            df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "            print(f\"    Scraped {len(df)} centers to {csv_path}\")\n",
    "        else:\n",
    "            print(\"     No table data found on page.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to scrape: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "911e026d-69be-4d53-a8d3-7b52a5839883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_census_tracts():\n",
    "    \"\"\"Fetches PA Census Tracts and filters for Philly.\"\"\"\n",
    "    print(\"  Fetching Philadelphia Census Tracts...\")\n",
    "    # PA State FIPS = 42\n",
    "    url = \"https://www2.census.gov/geo/tiger/TIGER2021/TRACT/tl_2021_42_tract.zip\"\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS)\n",
    "        if r.status_code == 200:\n",
    "            with ZipFile(BytesIO(r.content)) as z:\n",
    "                z.extractall(DATA_DIR / \"temp_tracts\")\n",
    "            \n",
    "            # Read and filter\n",
    "            shp_path = DATA_DIR / \"temp_tracts\" / \"tl_2021_42_tract.shp\"\n",
    "            gdf = gpd.read_file(shp_path)\n",
    "            # Filter for Philly (County Code 101)\n",
    "            philly_tracts = gdf[gdf['COUNTYFP'] == '101']\n",
    "            \n",
    "            output_path = DATA_DIR / \"philly_tracts.geojson\"\n",
    "            philly_tracts.to_file(output_path, driver=\"GeoJSON\")\n",
    "            print(f\"    Saved {len(philly_tracts)} tracts to {output_path}\")\n",
    "        else:\n",
    "            print(f\"    API Error: {r.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch tracts: {e}\")\n",
    "\n",
    "def fetch_hud_qct():\n",
    "    \"\"\"Fetches HUD QCT via ArcGIS FeatureServer.\"\"\"\n",
    "    print(\"  Fetching HUD Qualified Census Tracts (QCT)...\")\n",
    "    # Corrected URL for the HUD Feature Service\n",
    "    url = \"https://services.arcgis.com/g1fRTDLeMgspWrYp/arcgis/rest/services/QCTs/FeatureServer/0/query\"\n",
    "    \n",
    "    params = {\n",
    "        'where': \"STATE='42' AND COUNTY='101'\", # PA, Philly\n",
    "        'outFields': '*',\n",
    "        'f': 'geojson'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=HEADERS)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            # Check if features exist\n",
    "            if 'features' in data and len(data['features']) > 0:\n",
    "                gdf = gpd.GeoDataFrame.from_features(data['features'])\n",
    "                output_path = DATA_DIR / \"hud_qct.geojson\"\n",
    "                gdf.to_file(output_path, driver=\"GeoJSON\")\n",
    "                print(f\"    Saved {len(gdf)} QCT records to {output_path}\")\n",
    "            else:\n",
    "                print(\"     No QCT records returned. Check query parameters.\")\n",
    "        else:\n",
    "            print(f\"    API Error: {r.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch HUD QCT: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f1a6a9-6410-4867-ad4a-0f47bdcac8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_road_network():\n",
    "    \"\"\"Fetches drive network.\"\"\"\n",
    "    print(\"  Downloading Road Network...\")\n",
    "    output_path = DATA_DIR / \"philly_drive_network.graphml\"\n",
    "    \n",
    "    # Check if it already exists to save time\n",
    "    if output_path.exists():\n",
    "        print(f\"    Network already exists at {output_path}. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        G = ox.graph_from_place(\"Philadelphia, PA\", network_type='drive')\n",
    "        ox.save_graphml(G, output_path)\n",
    "        print(f\"    Saved road network to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch network: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0cccd-6a8d-4adf-a49e-c358e4f5a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\" STARTING PIPELINE V2\")\n",
    "    print(f\" Data Directory: {DATA_DIR}\\n\")\n",
    "    \n",
    "    fetch_hospitals()\n",
    "    scrape_urgent_care_backup()\n",
    "    fetch_census_tracts()\n",
    "    fetch_hud_qct()\n",
    "    fetch_road_network()\n",
    "    \n",
    "    print(\"\\n DONE! Check your 'data/raw' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880c59c-9a90-4e97-be98-89afa94727ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f72b8f-161b-461d-a0b4-8376ba55c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = false;\n",
       "  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = true;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        let retries = 0;\n",
       "        const open = () => {\n",
       "          if (comm.active) {\n",
       "            comm.open();\n",
       "          } else if (retries > 3) {\n",
       "            console.warn('Comm target never activated')\n",
       "          } else {\n",
       "            retries += 1\n",
       "            setTimeout(open, 500)\n",
       "          }\n",
       "        }\n",
       "        if (comm.active) {\n",
       "          comm.open();\n",
       "        } else {\n",
       "          setTimeout(open, 500)\n",
       "        }\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        })\n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='a218f5b7-4e4e-4d64-ab55-f48808285b73'>\n",
       "  <div id=\"ba46eb12-29a4-4b3c-b555-7dcf53ee887c\" data-root-id=\"a218f5b7-4e4e-4d64-ab55-f48808285b73\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"19b1d51e-1018-4819-b351-174a49bc175d\":{\"version\":\"3.8.0\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"760ac44f-560e-4798-ba22-d40c6a6cdee4\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"b8c7bdac-4e9c-441f-b8d5-ad5319bee083\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"a218f5b7-4e4e-4d64-ab55-f48808285b73\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"26376d49-5c7d-4d96-ae41-945073a842a5\",\"attributes\":{\"plot_id\":\"a218f5b7-4e4e-4d64-ab55-f48808285b73\",\"comm_id\":\"5326ce1b03af46fca74a71f02f5bc43d\",\"client_comm_id\":\"21aaed157aac499587870eb96153823c\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"19b1d51e-1018-4819-b351-174a49bc175d\",\"roots\":{\"a218f5b7-4e4e-4d64-ab55-f48808285b73\":\"ba46eb12-29a4-4b3c-b555-7dcf53ee887c\"},\"root_ids\":[\"a218f5b7-4e4e-4d64-ab55-f48808285b73\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "a218f5b7-4e4e-4d64-ab55-f48808285b73"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment Configured.\n",
      " Projection Set: EPSG:32129 (Pennsylvania South - Meters)\n",
      " Output Folders Ready: ['01_missteps_edge_effects', '02_intermediate_process', '03_final_deliverables']\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pn.extension() # Initialize Panel for interactive plots\n",
    "\n",
    "# 2. Path Configuration\n",
    "# Use relative path or your specific absolute path\n",
    "BASE_DIR = Path(r\".\") \n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# 3. Create Specific Output Directories\n",
    "DIRS = {\n",
    "    \"error\": RESULTS_DIR / \"01_missteps_edge_effects\",\n",
    "    \"process\": RESULTS_DIR / \"02_intermediate_process\",\n",
    "    \"final\": RESULTS_DIR / \"03_final_deliverables\"\n",
    "}\n",
    "\n",
    "for d in DIRS.values():\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4. Coordinate Reference System (CRS) Settings\n",
    "# User requested EPSG:2272, but also requested \"Meters\".\n",
    "# EPSG:2272 is PA South (US Feet). \n",
    "# EPSG:32129 is PA South (Meters). \n",
    "# We use 32129 to satisfy the \"Meters\" requirement for scientific accuracy.\n",
    "CRS_METRIC = \"EPSG:32129\" \n",
    "CRS_VISUAL = \"EPSG:3857\"   # Web Mercator (Required for Contextily Basemaps)\n",
    "\n",
    "# 5. Plotting Aesthetics\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['figure.dpi'] = 300 # High resolution for publication\n",
    "\n",
    "print(f\" Environment Configured.\")\n",
    "print(f\" Projection Set: {CRS_METRIC} (Pennsylvania South - Meters)\")\n",
    "print(f\" Output Folders Ready: {[d.name for d in DIRS.values()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65d3247-3187-443a-a4a0-32d87a81e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing WorldPop Raster...\n",
      "   ...Clipping raster to Philadelphia boundary...\n",
      "    Clipped raster saved to: data\\processed\\philly_pop_clipped.tif\n",
      "   ...Calculating Zonal Statistics...\n",
      "    Zonal stats calculated. Saved comparison data to: data\\processed\\tracts_census_vs_worldpop.geojson\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "from shapely.geometry import mapping\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration (Ensure these match your project structure)\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_RAW = DATA_DIR / \"raw\"\n",
    "DATA_PROCESSED = DATA_DIR / \"processed\"\n",
    "\n",
    "# Ensure directories exist\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def process_worldpop_raster():\n",
    "    \"\"\"\n",
    "    Task 2: Clip WorldPop Raster and Calculate Zonal Statistics (Fixed Version)\n",
    "    \"\"\"\n",
    "    print(\" Processing WorldPop Raster...\")\n",
    "    \n",
    "    # Define paths\n",
    "    # Ensure the filename matches exactly what you downloaded\n",
    "    raster_path = DATA_RAW / \"usa_pop_2020_CN_100m_R2025A_v1.tif\" \n",
    "    tracts_path = DATA_PROCESSED / \"tracts_svi_projected.geojson\"\n",
    "    \n",
    "    if not raster_path.exists():\n",
    "        print(f\"    WorldPop file not found at {raster_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 1. Read Boundary Data (Tracts) and Convert to WGS84\n",
    "    # WorldPop data is usually in EPSG:4326 (Lat/Lon), so we match the vector data to the raster.\n",
    "    gdf = gpd.read_file(tracts_path)\n",
    "    gdf_wgs = gdf.to_crs(epsg=4326) \n",
    "    \n",
    "    # [CRITICAL FIX] Create a unified boundary for clipping\n",
    "    # Use mapping() to convert the Shapely geometry object into the GeoJSON format required by Rasterio\n",
    "    union_geom = gdf_wgs.unary_union\n",
    "    philly_shape = [mapping(union_geom)] \n",
    "    \n",
    "    try:\n",
    "        # 2. Clip the Raster\n",
    "        print(\"   ...Clipping raster to Philadelphia boundary...\")\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            out_image, out_transform = mask(src, philly_shape, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "            \n",
    "        # Update metadata for the clipped file\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "        \n",
    "        # Save Clipped Raster\n",
    "        clipped_path = DATA_PROCESSED / \"philly_pop_clipped.tif\"\n",
    "        with rasterio.open(clipped_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "        print(f\"    Clipped raster saved to: {clipped_path}\")\n",
    "        \n",
    "        # 3. Calculate Zonal Statistics\n",
    "        # Sum pixel values within each tract polygon to estimate population\n",
    "        print(\"   ...Calculating Zonal Statistics...\")\n",
    "        stats = zonal_stats(gdf_wgs, clipped_path, stats=\"sum\")\n",
    "        \n",
    "        # Assign results back to the GeoDataFrame\n",
    "        gdf['worldpop_sum'] = [s['sum'] for s in stats]\n",
    "        \n",
    "        # Save Comparison Data\n",
    "        output_path = DATA_PROCESSED / \"tracts_census_vs_worldpop.geojson\"\n",
    "        gdf.to_file(output_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Zonal stats calculated. Saved comparison data to: {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Raster processing failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # If you have the census function defined elsewhere, you can call it here:\n",
    "    # fetch_and_merge_census_pop()\n",
    "    process_worldpop_raster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c0f89d1-b580-43fa-a971-601e72dfe9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetching Real Population from Census API...\n",
      "    Aggregated population for 408 tracts.\n",
      "    Saved updated tracts with REAL population to: data\\processed\\tracts_pop_svi_projected.geojson\n"
     ]
    }
   ],
   "source": [
    "CENSUS_API_KEY = \"02cfb7601cb4d601454bee8c28d14d90211b5baf\" \n",
    "\n",
    "TARGET_CRS = \"EPSG:32129\" # PA South (Meters)\n",
    "\n",
    "def fetch_and_merge_census_pop():\n",
    "    \"\"\"\n",
    "    Task 1: Fetch Block Group population from Census API, aggregate, and merge to Tracts.\n",
    "    \"\"\"\n",
    "    print(\" Fetching Real Population from Census API...\")\n",
    "    \n",
    "    # 1. API Request (2021 ACS 5-Year, Variable B01003_001E = Total Population)\n",
    "    # We request block group data to ensure high granularity, then aggregate up.\n",
    "    url = f\"https://api.census.gov/data/2021/acs/acs5?get=B01003_001E&for=block%20group:*&in=state:42%20county:101&key={CENSUS_API_KEY}\"\n",
    "    \n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"API Error: {resp.status_code} {resp.text}\")\n",
    "            \n",
    "        data = resp.json()\n",
    "        # Create DataFrame (skip the first row which is the header)\n",
    "        df = pd.DataFrame(data[1:], columns=data[0]) \n",
    "        \n",
    "        # 2. Data Cleaning\n",
    "        df['population'] = df['B01003_001E'].astype(int)\n",
    "        \n",
    "        # Construct GEOID: state(2) + county(3) + tract(6)\n",
    "        # We need to aggregate to Tract level (first 11 digits) from Block Groups\n",
    "        df['tract_geoid'] = df['state'] + df['county'] + df['tract']\n",
    "        \n",
    "        # 3. Groupby Aggregation (Summing Block Groups into Tracts)\n",
    "        df_tract_pop = df.groupby('tract_geoid')['population'].sum().reset_index()\n",
    "        print(f\"    Aggregated population for {len(df_tract_pop)} tracts.\")\n",
    "        \n",
    "        # 4. Merge into existing Tracts GeoJSON\n",
    "        tracts_path = DATA_PROCESSED / \"tracts_svi_projected.geojson\"\n",
    "        \n",
    "        if not tracts_path.exists():\n",
    "            print(f\"    Error: File not found at {tracts_path}\")\n",
    "            return None\n",
    "\n",
    "        gdf_tracts = gpd.read_file(tracts_path)\n",
    "        \n",
    "        # Ensure Key types match for merging\n",
    "        # Identify the correct column for GEOID in the shapefile\n",
    "        geoid_col = 'GEOID' if 'GEOID' in gdf_tracts.columns else 'GEOID20'\n",
    "        \n",
    "        # If the file was merged with SVI previously, it might use 'FIPS'\n",
    "        if 'FIPS' in gdf_tracts.columns:\n",
    "            left_key = 'FIPS'\n",
    "        else:\n",
    "            left_key = geoid_col\n",
    "            \n",
    "        # Convert to string to ensure matching works\n",
    "        gdf_tracts[left_key] = gdf_tracts[left_key].astype(str)\n",
    "        \n",
    "        # Merge\n",
    "        gdf_final = gdf_tracts.merge(df_tract_pop, left_on=left_key, right_on='tract_geoid', how='left')\n",
    "        \n",
    "        # Fill missing values (just in case some tracts have no population data)\n",
    "        gdf_final['population'] = gdf_final['population'].fillna(0)\n",
    "        \n",
    "        # Save\n",
    "        out_path = DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\"\n",
    "        gdf_final.to_file(out_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Saved updated tracts with REAL population to: {out_path}\")\n",
    "        return gdf_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch census population: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_merge_census_pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a370b4-9b85-43f4-8ae6-1e11a05bc9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db84ca9a-65ab-4f8d-95a5-ff7961a53968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STARTING DATA PREPROCESSING...\n",
      " Processing Supply Data (Hospitals & Health Centers)...\n",
      "    Geocoding 9 scraped addresses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1930 S Broad St., Fl. 2Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 403\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderInsufficientPrivileges: Non-successful status code 403\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1930 S Broad St., Fl. 2Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n",
      "    response = conn.getresponse()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connection.py\", line 565, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\socket.py\", line 717, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\ssl.py\", line 1307, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\ssl.py\", line 1163, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1930+S+Broad+St.%2C+Fl.+2Philadelphia%2C+PA+19145&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\adapters.py\", line 677, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1930+S+Broad+St.%2C+Fl.+2Philadelphia%2C+PA+19145&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1930+S+Broad+St.%2C+Fl.+2Philadelphia%2C+PA+19145&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1930 S Broad St., Fl. 2Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1700 S. Broad St.Unit 201Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1700 S. Broad St.Unit 201Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1700 S. Broad St.Unit 201Philadelphia, PA 19145',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('555 S. 43rd St.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('555 S. 43rd St.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('555 S. 43rd St.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('4400 Haverford Ave.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('4400 Haverford Ave.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('4400 Haverford Ave.Philadelphia, PA 19104',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1900 N 20th St.Philadelphia, PA 19121',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1900 N 20th St.Philadelphia, PA 19121',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1900 N 20th St.Philadelphia, PA 19121',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('301 W. Girard Ave.Philadelphia, PA 19123',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('301 W. Girard Ave.Philadelphia, PA 19123',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('301 W. Girard Ave.Philadelphia, PA 19123',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('131 E. Chelten Ave.Philadelphia, PA 19144',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('131 E. Chelten Ave.Philadelphia, PA 19144',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('131 E. Chelten Ave.Philadelphia, PA 19144',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('2230 Cottman Ave.Philadelphia, PA 19149',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('2230 Cottman Ave.Philadelphia, PA 19149',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 403\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderInsufficientPrivileges: Non-successful status code 403\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('2230 Cottman Ave.Philadelphia, PA 19149',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n",
      "    response = conn.getresponse()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connection.py\", line 565, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\http\\client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\socket.py\", line 717, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\ssl.py\", line 1307, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\ssl.py\", line 1163, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 871, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=2230+Cottman+Ave.Philadelphia%2C+PA+19149&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\requests\\adapters.py\", line 677, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=2230+Cottman+Ave.Philadelphia%2C+PA+19149&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=2230+Cottman+Ave.Philadelphia%2C+PA+19149&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('2840 West Dauphin St.Philadelphia, PA 19132',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('2840 West Dauphin St.Philadelphia, PA 19132',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('2840 West Dauphin St.Philadelphia, PA 19132',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\adapters.py\", line 500, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 503\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderTimedOut: Non-successful status code 503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved merged facilities to data\\processed\\facilities_projected.geojson\n",
      "map Processing Demand Data (Tracts & SVI)...\n",
      "    Saved SVI-enriched tracts to data\\processed\\tracts_svi_projected.geojson\n",
      "  Processing HUD QCT...\n",
      "    Saved projected QCT to data\\processed\\qct_projected.geojson\n",
      "\n",
      " Preprocessing Complete! Ready for Analysis.\n"
     ]
    }
   ],
   "source": [
    "TARGET_CRS = \"EPSG:32129\"\n",
    "\n",
    "def process_supply_data():\n",
    "    print(\" Processing Supply Data (Hospitals & Health Centers)...\")\n",
    "    \n",
    "    # 1. Process official hospital data (GeoJSON)\n",
    "    hosp_path = DATA_RAW / \"phl_hospitals.geojson\"\n",
    "    if hosp_path.exists():\n",
    "        gdf_hosp = gpd.read_file(hosp_path)\n",
    "        # Keep only useful columns\n",
    "        cols = ['HOSPITAL_NAME', 'HOSPITAL_TYPE', 'BEDS', 'geometry']\n",
    "        # Adjust if column names differ. Try automatic matching of common names.\n",
    "        available_cols = [c for c in cols if c in gdf_hosp.columns]\n",
    "        gdf_hosp = gdf_hosp[available_cols]\n",
    "        gdf_hosp['facility_type'] = 'Hospital'\n",
    "        gdf_hosp = gdf_hosp.to_crs(TARGET_CRS)\n",
    "    else:\n",
    "        print(\"    Missing Hospital Data!\")\n",
    "        gdf_hosp = gpd.GeoDataFrame()\n",
    "\n",
    "    # 2. Process scraped health centers (CSV -> Geocoding)\n",
    "    center_path = DATA_RAW / \"scraped_health_centers.csv\"\n",
    "    if center_path.exists():\n",
    "        df_centers = pd.read_csv(center_path)\n",
    "        print(f\"    Geocoding {len(df_centers)} scraped addresses...\")\n",
    "        \n",
    "        # Initialize geocoder\n",
    "        geolocator = Nominatim(user_agent=\"philly_health_access_study\")\n",
    "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "        \n",
    "        # Execute conversion\n",
    "        df_centers['location'] = df_centers['address'].apply(geocode)\n",
    "        df_centers['point'] = df_centers['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "        \n",
    "        # Remove failed entries\n",
    "        df_centers = df_centers.dropna(subset=['point'])\n",
    "        \n",
    "        # Create GeoDataFrame\n",
    "        # Point format is usually (lat, lon, altitude), we need (lon, lat)\n",
    "        df_centers['geometry'] = df_centers['point'].apply(lambda x: gpd.points_from_xy([x[1]], [x[0]])[0])\n",
    "        gdf_centers = gpd.GeoDataFrame(df_centers, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        \n",
    "        gdf_centers['facility_type'] = 'City Health Center'\n",
    "        # Unify projection\n",
    "        gdf_centers = gdf_centers.to_crs(TARGET_CRS)\n",
    "        \n",
    "        # Merge hospitals and health centers\n",
    "        gdf_facilities = pd.concat([gdf_hosp, gdf_centers], ignore_index=True)\n",
    "        \n",
    "        # Save\n",
    "        out_path = DATA_PROCESSED / \"facilities_projected.geojson\"\n",
    "        gdf_facilities.to_file(out_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Saved merged facilities to {out_path}\")\n",
    "    else:\n",
    "        print(\"    Missing Scraped Center Data!\")\n",
    "\n",
    "def process_demand_data():\n",
    "    print(\"map Processing Demand Data (Tracts & SVI)...\")\n",
    "    \n",
    "    # 1. Read Census Tracts\n",
    "    tract_path = DATA_RAW / \"philly_tracts.geojson\"\n",
    "    if not tract_path.exists():\n",
    "        print(\"    Tract data missing.\")\n",
    "        return\n",
    "    \n",
    "    gdf_tracts = gpd.read_file(tract_path)\n",
    "    \n",
    "    # Ensure GEOID is string format for merging\n",
    "    # Column name might be 'GEOID' or 'GEOID20' depending on the year\n",
    "    geoid_col = 'GEOID' if 'GEOID' in gdf_tracts.columns else 'GEOID20'\n",
    "    gdf_tracts[geoid_col] = gdf_tracts[geoid_col].astype(str)\n",
    "    \n",
    "    # 2. Read SVI Data (CSV)\n",
    "    svi_path = DATA_RAW / \"philly_svi_2020.csv\"\n",
    "    if svi_path.exists():\n",
    "        df_svi = pd.read_csv(svi_path)\n",
    "        \n",
    "        # SVI FIPS column is usually 'FIPS'. If numeric, convert to string and pad with zeros.\n",
    "        # Philly FIPS starts with 42101, length should be 11 digits.\n",
    "        df_svi['FIPS'] = df_svi['FIPS'].astype(str).str.zfill(11)\n",
    "        \n",
    "        # Select key indicators (RPL_THEMES is the overall SVI index)\n",
    "        # RPL_THEME1: Socioeconomic, RPL_THEME2: Household Comp, etc.\n",
    "        svi_cols = ['FIPS', 'RPL_THEMES', 'RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4']\n",
    "        df_svi_clean = df_svi[svi_cols].copy()\n",
    "        \n",
    "        # 3. Merge data\n",
    "        gdf_merged = gdf_tracts.merge(df_svi_clean, left_on=geoid_col, right_on='FIPS', how='left')\n",
    "        \n",
    "        # Fill missing values (just in case)\n",
    "        gdf_merged['RPL_THEMES'] = gdf_merged['RPL_THEMES'].fillna(-999) # -999 indicates missing\n",
    "        \n",
    "        # Unify projection\n",
    "        gdf_merged = gdf_merged.to_crs(TARGET_CRS)\n",
    "        \n",
    "        # Save\n",
    "        out_path = DATA_PROCESSED / \"tracts_svi_projected.geojson\"\n",
    "        gdf_merged.to_file(out_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Saved SVI-enriched tracts to {out_path}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"    SVI CSV missing! Please download it manually as instructed.\")\n",
    "\n",
    "def process_qct_data():\n",
    "    print(\"  Processing HUD QCT...\")\n",
    "    qct_path = DATA_RAW / \"hud_qct.geojson\"\n",
    "    if qct_path.exists():\n",
    "        gdf_qct = gpd.read_file(qct_path)\n",
    "        gdf_qct = gdf_qct.to_crs(TARGET_CRS)\n",
    "        \n",
    "        out_path = DATA_PROCESSED / \"qct_projected.geojson\"\n",
    "        gdf_qct.to_file(out_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Saved projected QCT to {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" STARTING DATA PREPROCESSING...\")\n",
    "    process_supply_data()\n",
    "    process_demand_data()\n",
    "    process_qct_data()\n",
    "    print(\"\\n Preprocessing Complete! Ready for Analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8670e14-6d06-4880-b62f-40d61d5ef4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f1611-3ecc-4bf6-9821-e64f11a4ddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf93681-3f1c-442b-baa7-52565354fb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e27601ae-3637-45a6-b1e9-1ef9ca9760e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enriching Facilities with Real CMS Medicaid Data...\n",
      "    Loaded 187 PA hospitals from CMS database.\n",
      "    Matched 85 hospitals with CMS records.\n",
      "    Health Centers manually set to True.\n",
      "    Total Medicaid-Accepting Facilities: 85 / 146\n",
      "    Updated facilities file saved.\n"
     ]
    }
   ],
   "source": [
    "from difflib import get_close_matches\n",
    "CMS_FILE = DATA_RAW / \"cms_hospitals.csv\"\n",
    "FACILITIES_FILE = DATA_PROCESSED / \"facilities_with_buffer.geojson\" \n",
    "\n",
    "def enrich_facilities_with_cms():\n",
    "    print(\" Enriching Facilities with Real CMS Medicaid Data...\")\n",
    "    \n",
    "    if not CMS_FILE.exists():\n",
    "        print(\" CMS File not found. Please download 'Hospital General Information.csv' from CMS.gov\")\n",
    "        print(\"   Place it in data/raw/ and rename to 'cms_hospitals.csv'\")\n",
    "        print(\"    Falling back to Random Simulation for now...\")\n",
    "        return False\n",
    "\n",
    "    # 1. Read CMS Data\n",
    "    # Logic: If it is in the CMS database and matches criteria, we assume it accepts public insurance.\n",
    "    try:\n",
    "        df_cms = pd.read_csv(CMS_FILE, encoding='latin1') \n",
    "        # Simplify: Keep only PA hospitals\n",
    "        df_cms = df_cms[df_cms['State'] == 'PA']\n",
    "        \n",
    "        # Extract facility names\n",
    "        cms_names = df_cms['Facility Name'].str.upper().tolist()\n",
    "        \n",
    "        print(f\"    Loaded {len(cms_names)} PA hospitals from CMS database.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error reading CMS CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 2. Read Local Facilities Data\n",
    "    gdf_fac = gpd.read_file(FACILITIES_FILE)\n",
    "    \n",
    "    # 3. Fuzzy Match\n",
    "    # Match OpenDataPhilly names vs CMS names (e.g., \"Hosp of Univ of PA\" vs \"HOSPITAL OF THE UPENN\")\n",
    "    \n",
    "    matched_count = 0\n",
    "    accepts_list = []\n",
    "    \n",
    "    for i, row in gdf_fac.iterrows():\n",
    "        local_name = str(row['name']).upper()\n",
    "        \n",
    "        # Skip unknown names in buffer\n",
    "        if \"UNKNOWN\" in local_name:\n",
    "            accepts_list.append(False) \n",
    "            continue\n",
    "            \n",
    "        # Find closest match in CMS list\n",
    "        matches = get_close_matches(local_name, cms_names, n=1, cutoff=0.6)\n",
    "        \n",
    "        if matches:\n",
    "            # Found! It is a CMS certified hospital\n",
    "            accepts_list.append(True)\n",
    "            matched_count += 1\n",
    "        else:\n",
    "            # Not found. Might be private practice or specialty.\n",
    "            # Exception: Public Health Centers should be True.\n",
    "            if \"HEALTH CENTER\" in local_name:\n",
    "                accepts_list.append(True) \n",
    "            else:\n",
    "                accepts_list.append(False)\n",
    "    \n",
    "    gdf_fac['accepts_medicaid'] = accepts_list\n",
    "    \n",
    "    print(f\"    Matched {matched_count} hospitals with CMS records.\")\n",
    "    print(f\"    Health Centers manually set to True.\")\n",
    "    print(f\"    Total Medicaid-Accepting Facilities: {sum(accepts_list)} / {len(gdf_fac)}\")\n",
    "    \n",
    "    # Save\n",
    "    gdf_fac.to_file(FACILITIES_FILE, driver=\"GeoJSON\")\n",
    "    print(\"    Updated facilities file saved.\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    enrich_facilities_with_cms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fce270e-749c-43b5-bb86-f76db35bedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STARTING FINAL ANALYSIS...\n",
      "  Calculating OD Matrix...\n",
      " Phase 1: General Accessibility (All Facilities)\n",
      "   ...Calculating E2SFCA for subset: all\n",
      " Phase 2: Equity Accessibility (Medicaid Only)\n",
      "   ...Calculating E2SFCA for subset: medicaid\n",
      " Calculating Optimal New Sites (Gap Analysis)...\n",
      "\n",
      " Analysis Complete!\n",
      "   - Main Results: results\\final_E2SFCA_results.geojson\n",
      "   - Recommendations: results\\recommended_new_sites.geojson\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "BASE_DIR = Path(r\".\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_RAW = DATA_DIR / \"raw\"\n",
    "DATA_PROCESSED = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TARGET_CRS = \"EPSG:32129\"\n",
    "\n",
    "# E2SFCA Parameters\n",
    "GAUSSIAN_THRESHOLD = 30 \n",
    "BETA = - (GAUSSIAN_THRESHOLD**2) / np.log(0.01)\n",
    "\n",
    "def gaussian_weight(t_min):\n",
    "    if t_min > GAUSSIAN_THRESHOLD: return 0\n",
    "    return np.exp(- (t_min**2) / BETA)\n",
    "\n",
    "def calculate_od_matrix(G, tracts, facilities):\n",
    "    print(\"  Calculating OD Matrix...\")\n",
    "    tract_centroids = tracts.geometry.centroid\n",
    "    facility_points = facilities.geometry\n",
    "    \n",
    "    # Snap points to network\n",
    "    orig_nodes = ox.nearest_nodes(G, X=tract_centroids.x, Y=tract_centroids.y)\n",
    "    dest_nodes = ox.nearest_nodes(G, X=facility_points.x, Y=facility_points.y)\n",
    "    \n",
    "    unique_origs = list(set(orig_nodes))\n",
    "    od_times = {}\n",
    "    \n",
    "    # Calculate travel times\n",
    "    for o_node in unique_origs:\n",
    "        lengths = nx.single_source_dijkstra_path_length(\n",
    "            G, o_node, weight='travel_time', cutoff=(GAUSSIAN_THRESHOLD+5)*60\n",
    "        )\n",
    "        od_times[o_node] = lengths\n",
    "        \n",
    "    return orig_nodes, dest_nodes, od_times\n",
    "\n",
    "def run_e2sfca(tracts, facilities, orig_nodes, dest_nodes, od_times, subset_name=\"all\"):\n",
    "    print(f\"   ...Calculating E2SFCA for subset: {subset_name}\")\n",
    "    \n",
    "    # Determine population column\n",
    "    pop_col = 'population' if 'population' in tracts.columns else 'E_TOTPOP'\n",
    "    if pop_col not in tracts.columns: \n",
    "        tracts['dummy_pop'] = 1000\n",
    "        pop_col = 'dummy_pop'\n",
    "        \n",
    "    # Determine beds column\n",
    "    bed_col = 'BEDS'\n",
    "    if bed_col not in facilities.columns: \n",
    "        facilities[bed_col] = 1.0\n",
    "\n",
    "    # Step 1: Calculate R_j (Supply-to-Demand Ratio)\n",
    "    r_j_list = []\n",
    "    \n",
    "    # Use enumerate to align with dest_nodes list index\n",
    "    for idx, (original_idx, fac) in enumerate(facilities.iterrows()):\n",
    "        f_node = dest_nodes[idx] \n",
    "        cap = float(fac[bed_col]) if pd.notnull(fac[bed_col]) else 1.0\n",
    "        \n",
    "        weighted_pop = 0\n",
    "        for i, tract in tracts.iterrows():\n",
    "            t_node = orig_nodes[i]\n",
    "            if t_node in od_times and f_node in od_times[t_node]:\n",
    "                t_min = od_times[t_node][f_node] / 60\n",
    "                weighted_pop += tract[pop_col] * gaussian_weight(t_min)\n",
    "        \n",
    "        r_j_list.append(cap / weighted_pop if weighted_pop > 0 else 0)\n",
    "    \n",
    "    facilities[f'R_{subset_name}'] = r_j_list\n",
    "    \n",
    "    # Step 2: Calculate A_i (Accessibility Score)\n",
    "    access_scores = []\n",
    "    for i, tract in tracts.iterrows():\n",
    "        t_node = orig_nodes[i]\n",
    "        sum_r = 0\n",
    "        for idx, (original_idx, fac) in enumerate(facilities.iterrows()):\n",
    "            f_node = dest_nodes[idx]\n",
    "            if t_node in od_times and f_node in od_times[t_node]:\n",
    "                t_min = od_times[t_node][f_node] / 60\n",
    "                sum_r += fac[f'R_{subset_name}'] * gaussian_weight(t_min)\n",
    "        access_scores.append(sum_r * 1000)\n",
    "        \n",
    "    return access_scores\n",
    "\n",
    "def recommend_sites(df_res, pop_col):\n",
    "    print(\" Calculating Optimal New Sites (Gap Analysis)...\")\n",
    "    \n",
    "    # Social Vulnerability Index check\n",
    "    svi_col = 'RPL_THEMES' if 'RPL_THEMES' in df_res.columns else 'SVI'\n",
    "    if svi_col in df_res.columns:\n",
    "        svi_factor = df_res[svi_col].replace(-999, 0.5).fillna(0.5)\n",
    "    else:\n",
    "        svi_factor = 0.5\n",
    "        \n",
    "    # Prevent division by zero\n",
    "    access_safe = df_res['access_medicaid'].replace(0, 0.0001)\n",
    "    \n",
    "    # Gap Index = (Demand * Vulnerability) / Supply\n",
    "    df_res['gap_index'] = (df_res[pop_col] * svi_factor) / access_safe\n",
    "    \n",
    "    top_3 = df_res.nlargest(3, 'gap_index')\n",
    "    recs = top_3[['GEOID', 'gap_index', 'geometry', pop_col, 'access_medicaid']].copy()\n",
    "    recs['geometry'] = recs.geometry.centroid\n",
    "    recs['suggestion'] = [\"Priority Site #1\", \"Priority Site #2\", \"Priority Site #3\"]\n",
    "    \n",
    "    return recs\n",
    "\n",
    "def main():\n",
    "    print(\" STARTING FINAL ANALYSIS...\")\n",
    "    \n",
    "    # Load Data\n",
    "    tracts = gpd.read_file(DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\")\n",
    "    facilities = gpd.read_file(DATA_PROCESSED / \"facilities_with_buffer.geojson\")\n",
    "    \n",
    "    # Load Network\n",
    "    graph_path = DATA_RAW / \"philly_drive_network.graphml\"\n",
    "    G = ox.load_graphml(graph_path)\n",
    "    G = ox.project_graph(G, to_crs=TARGET_CRS)\n",
    "    G = ox.add_edge_speeds(G)\n",
    "    G = ox.add_edge_travel_times(G)\n",
    "    \n",
    "    # Pre-calculate OD Matrix\n",
    "    orig, dest, od = calculate_od_matrix(G, tracts, facilities)\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    print(\" Phase 1: General Accessibility (All Facilities)\")\n",
    "    scores_all = run_e2sfca(tracts, facilities, orig, dest, od, \"all\")\n",
    "    tracts['access_all'] = scores_all\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    print(\" Phase 2: Equity Accessibility (Medicaid Only)\")\n",
    "    if 'accepts_medicaid' in facilities.columns:\n",
    "        # [CRITICAL FIX] Must reset index so 'iterrows' aligns with dest_nodes list index\n",
    "        medicaid_facs = facilities[facilities['accepts_medicaid'] == True].copy().reset_index(drop=True)\n",
    "        \n",
    "        # Re-calculate destination nodes for this specific subset\n",
    "        dest_nodes_med = ox.nearest_nodes(G, X=medicaid_facs.geometry.x, Y=medicaid_facs.geometry.y)\n",
    "        \n",
    "        scores_med = run_e2sfca(tracts, medicaid_facs, orig, dest_nodes_med, od, \"medicaid\")\n",
    "        tracts['access_medicaid'] = scores_med\n",
    "    else:\n",
    "        print(\" 'accepts_medicaid' column missing. Skipping Phase 2.\")\n",
    "        tracts['access_medicaid'] = scores_all \n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # Site Recommendations\n",
    "    pop_col = 'population' if 'population' in tracts.columns else 'E_TOTPOP'\n",
    "    if pop_col not in tracts.columns: pop_col = 'dummy_pop'\n",
    "    \n",
    "    recs_gdf = recommend_sites(tracts, pop_col)\n",
    "    \n",
    "    # Output Files\n",
    "    out_res = RESULTS_DIR / \"final_E2SFCA_results.geojson\"\n",
    "    tracts.to_file(out_res, driver=\"GeoJSON\")\n",
    "    \n",
    "    out_rec = RESULTS_DIR / \"recommended_new_sites.geojson\"\n",
    "    recs_gdf.to_file(out_rec, driver=\"GeoJSON\")\n",
    "    \n",
    "    print(f\"\\n Analysis Complete!\")\n",
    "    print(f\"   - Main Results: {out_res}\")\n",
    "    print(f\"   - Recommendations: {out_rec}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e25d6-29c6-48ef-93ee-9c192f3cd10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d505ba9-40c1-4a72-a44d-525e06f0a7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb129f-b754-4a96-936b-1ffbfed3a481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fd0f1-580d-492a-859e-29b919c3de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9549076-7069-4e2c-a016-bbd4a73160fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e10a4c-9994-4b79-be62-425994e8ca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f610c562-f061-432e-8365-0a1a29932cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetching Buffer Hospitals (Using Bounding Box Strategy)...\n",
      "   ...Querying OSM within box (N:40.4, S:39.6, E:-74.7, W:-75.6)...\n",
      "   ...Downloaded 110 raw features. Cleaning...\n",
      "    Success! Total Facilities: 146\n",
      "      - Original Philly: 36\n",
      "      - Buffer Raw: 110\n",
      "      - After Deduplication: 146\n",
      "    Saved to: data\\processed\\facilities_with_buffer.geojson\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Project Configuration & Paths\n",
    "# ---------------------------------------------------------\n",
    "# Base directory of your project\n",
    "BASE_DIR = Path(\".\")\n",
    "\n",
    "# Data directories\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_RAW = DATA_DIR / \"raw\"\n",
    "DATA_PROCESSED = DATA_DIR / \"processed\"\n",
    "\n",
    "# Ensure processed directory exists\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Target Coordinate Reference System (UTM Zone 18N for PA/NJ - Meters)\n",
    "# We use this for accurate centroid calculation and distance measurement\n",
    "TARGET_CRS = \"EPSG:32129\"  # Or EPSG:32618\n",
    "\n",
    "def fetch_buffer_hospitals_robust():\n",
    "    \"\"\"\n",
    "    Robust Version: Fetches hospitals from the surrounding region (PA Suburbs + NJ)\n",
    "    using a Bounding Box to avoid timeouts and edge effects.\n",
    "    \"\"\"\n",
    "    print(\" Fetching Buffer Hospitals (Using Bounding Box Strategy)...\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Define Bounding Box (Philly + NJ + PA Suburbs)\n",
    "    # ---------------------------------------------------------\n",
    "    # Coordinates cover:\n",
    "    # North: Montgomery/Bucks | South: Gloucester (NJ)\n",
    "    # West: Chester/Delaware  | East: Burlington/Camden (NJ)\n",
    "    north, south = 40.40, 39.60\n",
    "    east, west = -74.70, -75.60\n",
    "    \n",
    "    tags = {'amenity': 'hospital'}\n",
    "    \n",
    "    try:\n",
    "        print(f\"   ...Querying OSM within box (N:{north}, S:{south}, E:{east}, W:{west})...\")\n",
    "        \n",
    "        gdf_buffer = None\n",
    "\n",
    "        # --- OSMnx Version Compatibility Check ---\n",
    "        if hasattr(ox, 'features_from_bbox'):\n",
    "            try:\n",
    "                gdf_buffer = ox.features_from_bbox(bbox=(north, south, east, west), tags=tags)\n",
    "            except TypeError:\n",
    "                gdf_buffer = ox.features_from_bbox(north, south, east, west, tags)\n",
    "        elif hasattr(ox, 'geometries_from_bbox'):\n",
    "            gdf_buffer = ox.geometries_from_bbox(north, south, east, west, tags)\n",
    "        else:\n",
    "            try:\n",
    "                gdf_buffer = ox.features.features_from_bbox(bbox=(north, south, east, west), tags=tags)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if gdf_buffer is None or len(gdf_buffer) == 0:\n",
    "             raise ValueError(\"No data returned from OSMnx.\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 3. Data Cleaning & Warning Fix\n",
    "        # ---------------------------------------------------------\n",
    "        print(f\"   ...Downloaded {len(gdf_buffer)} raw features. Cleaning...\")\n",
    "\n",
    "        # [CRITICAL FIX] \n",
    "        # Project to Meters (Target CRS) BEFORE calculating centroid.\n",
    "        # This fixes the \"Geometry is in a geographic CRS\" warning.\n",
    "        gdf_buffer = gdf_buffer.to_crs(TARGET_CRS)\n",
    "        \n",
    "        # Now it is safe to calculate centroids\n",
    "        gdf_buffer['geometry'] = gdf_buffer.geometry.centroid\n",
    "        \n",
    "        # Reset index\n",
    "        gdf_buffer = gdf_buffer.reset_index(drop=True)\n",
    "        \n",
    "        # Ensure 'name' column exists\n",
    "        if 'name' not in gdf_buffer.columns:\n",
    "            gdf_buffer['name'] = 'Unknown Buffer Hospital'\n",
    "            \n",
    "        # Keep only necessary columns\n",
    "        gdf_buffer = gdf_buffer[['name', 'geometry']].copy()\n",
    "        gdf_buffer['facility_type'] = 'Buffer Hospital'\n",
    "        \n",
    "        # Assign default bed count\n",
    "        gdf_buffer['BEDS'] = 150 \n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 4. Merge with Existing Philly Facilities\n",
    "        # ---------------------------------------------------------\n",
    "        philly_path = DATA_PROCESSED / \"facilities_projected.geojson\"\n",
    "        \n",
    "        if philly_path.exists():\n",
    "            philly_facilities = gpd.read_file(philly_path)\n",
    "            \n",
    "            # Ensure Philly data is in the same CRS\n",
    "            if philly_facilities.crs != TARGET_CRS:\n",
    "                philly_facilities = philly_facilities.to_crs(TARGET_CRS)\n",
    "\n",
    "            # Concatenate\n",
    "            combined_facilities = pd.concat([philly_facilities, gdf_buffer], ignore_index=True)\n",
    "            \n",
    "            # Deduplicate (Remove hospitals that are practically in the same spot)\n",
    "            # Round coordinates to nearest 1 meter to find duplicates\n",
    "            combined_facilities['x_round'] = combined_facilities.geometry.x.round(0)\n",
    "            combined_facilities['y_round'] = combined_facilities.geometry.y.round(0)\n",
    "            \n",
    "            combined_facilities = combined_facilities.drop_duplicates(subset=['x_round', 'y_round'])\n",
    "            combined_facilities = combined_facilities.drop(columns=['x_round', 'y_round'])\n",
    "            \n",
    "            # Save final file using the defined path constant\n",
    "            out_path = DATA_PROCESSED / \"facilities_with_buffer.geojson\"\n",
    "            combined_facilities.to_file(out_path, driver=\"GeoJSON\")\n",
    "            \n",
    "            print(f\"    Success! Total Facilities: {len(combined_facilities)}\")\n",
    "            print(f\"      - Original Philly: {len(philly_facilities)}\")\n",
    "            print(f\"      - Buffer Raw: {len(gdf_buffer)}\")\n",
    "            print(f\"      - After Deduplication: {len(combined_facilities)}\")\n",
    "            print(f\"    Saved to: {out_path}\")\n",
    "        else:\n",
    "            print(f\"    Error: Philly facilities file not found at {philly_path}\")\n",
    "            print(\"      Please run the previous processing step first.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to fetch buffer hospitals: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_buffer_hospitals_robust()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90b586-87cf-4613-b39b-4b7eb47de925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cccc9b-3a9f-40fa-a97e-f01df9a77816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70957b-d836-479d-be23-e14308b940e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9f7ec-89f5-4ddc-ac8d-cc227053063d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e25c31-6a5f-43a6-adeb-cd8ea4fed1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "092e92bd-4a8c-46ab-b0db-d41320255fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_publication_map(gdf, column, title, output_path, cmap='viridis', scheme='FisherJenks', k=5, kind='area', add_basemap=True):\n",
    "    \"\"\"\n",
    "    Generates a high-quality, scientifically rigorous map.\n",
    "    Handles projection, basemaps, scale bars, and legends automatically.\n",
    "    \"\"\"\n",
    "    # 1. Reproject to Web Mercator for Basemap compatibility\n",
    "    gdf_plot = gdf.to_crs(CRS_VISUAL)\n",
    "    \n",
    "    # 2. Setup Figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # 3. Plot Data based on Type\n",
    "    if kind == 'area':\n",
    "        # Handle NaN values to prevent plotting errors\n",
    "        if column in gdf_plot.columns:\n",
    "            gdf_plot = gdf_plot.dropna(subset=[column])\n",
    "            \n",
    "        gdf_plot.plot(\n",
    "            column=column,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            scheme=scheme,\n",
    "            k=k,\n",
    "            alpha=0.7,\n",
    "            edgecolor='white',\n",
    "            linewidth=0.2,\n",
    "            legend=True,\n",
    "            legend_kwds={\n",
    "                'loc': 'lower right',\n",
    "                'title': \"Legend\",\n",
    "                'frameon': True,\n",
    "                'fmt': '{:.2f}', # Force 2 decimal places (e.g., 0.55 instead of 0.55432)\n",
    "                'bbox_to_anchor': (1, 0.25)\n",
    "            }\n",
    "        )\n",
    "    elif kind == 'point':\n",
    "        gdf_plot.plot(\n",
    "            ax=ax,\n",
    "            color='#d62728', # Scientific Red\n",
    "            markersize=200,\n",
    "            edgecolor='white',\n",
    "            linewidth=1.5,\n",
    "            marker='*',\n",
    "            zorder=10,\n",
    "            label='Proposed Locations'\n",
    "        )\n",
    "        # Manually add legend for points\n",
    "        ax.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "    # 4. Add Basemap (CartoDB Positron - Clean and Scientific)\n",
    "    if add_basemap:\n",
    "        try:\n",
    "            ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "        except Exception as e:\n",
    "            print(f\" Basemap warning: {e}\")\n",
    "\n",
    "    # 5. Scientific Annotations\n",
    "    # Title\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # North Arrow (Simulated)\n",
    "    x, y, arrow_length = 0.05, 0.95, 0.1\n",
    "    ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "                arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "                ha='center', va='center', fontsize=20, xycoords=ax.transAxes)\n",
    "\n",
    "    # Scale Bar (Approximation based on CRS units)\n",
    "    # Since we projected to 3857 (Meters), we can use matplotlib_scalebar\n",
    "    scalebar = ScaleBar(1, \"m\", location=\"lower left\", box_alpha=0.5)\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    # Source Credit\n",
    "    plt.figtext(0.5, 0.05, \"Data Sources: OpenStreetMap, CDC SVI 2020, CMS Hospital Data | Projection: EPSG:32129\", \n",
    "                ha='center', fontsize=8, color='#555555')\n",
    "\n",
    "    # 6. Clean Axis\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # 7. Save\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close() # Close plot to free memory\n",
    "    print(f\" Saved: {output_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a7b33-c6d4-4474-9dca-6106ebe3af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b48c8b00-8ed8-4d97-beed-9f165eb688d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Module 1: Visualizing the Edge Effect Bias...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14175\\AppData\\Local\\Temp\\ipykernel_6864\\2111117143.py:21: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  philly_boundary = tracts.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corrected Edge Effect map generated at: results\\01_missteps_edge_effects\\01_error_edge_effect_demonstration_fixed.png\n"
     ]
    }
   ],
   "source": [
    "def module_1_demonstrate_error():\n",
    "    print(\" Module 1: Visualizing the Edge Effect Bias...\")\n",
    "    \n",
    "    # Load Data\n",
    "    tracts_path = DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\"\n",
    "    fac_path = DATA_PROCESSED / \"facilities_with_buffer.geojson\"\n",
    "    \n",
    "    if not fac_path.exists():\n",
    "        print(\" Data missing. Please run previous data processing steps.\")\n",
    "        return\n",
    "\n",
    "    # Load and ensure Metric CRS for accurate spatial calculations\n",
    "    tracts = gpd.read_file(tracts_path).to_crs(CRS_METRIC)\n",
    "    facilities = gpd.read_file(fac_path).to_crs(CRS_METRIC)\n",
    "    \n",
    "    # --- FIX: SPATIAL FILTERING ---\n",
    "    # Instead of relying on the 'facility_type' column (which may have errors),\n",
    "    # we determine the status based on actual location geometry.\n",
    "    \n",
    "    # 1. Create a unified polygon for the Philadelphia boundary\n",
    "    philly_boundary = tracts.unary_union\n",
    "    \n",
    "    # 2. Check which facilities are strictly INSIDE the boundary\n",
    "    # This returns a boolean (True/False) series\n",
    "    is_inside_philly = facilities.geometry.within(philly_boundary)\n",
    "    \n",
    "    # 3. Split the data based on geometry\n",
    "    philly_only_facs = facilities[is_inside_philly]  # Strictly Inside\n",
    "    buffer_facs = facilities[~is_inside_philly]      # Strictly Outside (The Inverse)\n",
    "    \n",
    "    # --- VISUALIZATION ---\n",
    "    output_path = DIRS[\"error\"] / \"01_error_edge_effect_demonstration_fixed.png\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Plot Tracts (The Grey City Area)\n",
    "    tracts.to_crs(CRS_VISUAL).plot(ax=ax, color='#f0f0f0', edgecolor='#cccccc')\n",
    "    \n",
    "    # Plot Philadelphia Facilities (Blue Dots) - strictly inside\n",
    "    philly_only_facs.to_crs(CRS_VISUAL).plot(\n",
    "        ax=ax, \n",
    "        color='blue', \n",
    "        markersize=30, \n",
    "        label='Philadelphia Hospitals (Included)', \n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Plot Buffer Facilities (Red X) - strictly outside\n",
    "    buffer_facs.to_crs(CRS_VISUAL).plot(\n",
    "        ax=ax, \n",
    "        color='red', \n",
    "        marker='x', \n",
    "        markersize=50, \n",
    "        label='IGNORED Buffer Hospitals', \n",
    "        alpha=0.9\n",
    "    )\n",
    "    \n",
    "    # Add Basemap for context\n",
    "    try:\n",
    "        ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    except Exception as e:\n",
    "        print(f\" Could not load basemap: {e}\")\n",
    "    \n",
    "    ax.set_title(\n",
    "        \"Methodological Flaw: The Edge Effect\\n(Red 'X' marks are facilities outside the city boundary)\", \n",
    "        fontsize=14, \n",
    "        color='darkred'\n",
    "    )\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" Corrected Edge Effect map generated at: {output_path}\")\n",
    "\n",
    "module_1_demonstrate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767afa6-f278-4f49-9887-8e780f36dd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d43529ef-87bd-4cf9-b171-7444b7c20784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Module 2: Generating Intermediate Process Maps...\n",
      " Saved: 02_process_SVI_distribution.png\n",
      " Saved: 02_process_pop_density.png\n"
     ]
    }
   ],
   "source": [
    "def module_2_visualize_process():\n",
    "    print(\" Module 2: Generating Intermediate Process Maps...\")\n",
    "    \n",
    "    tract_path = DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\"\n",
    "    gdf = gpd.read_file(tract_path).to_crs(CRS_METRIC)\n",
    "    \n",
    "    # Clean SVI Data\n",
    "    if 'RPL_THEMES' in gdf.columns:\n",
    "        gdf['SVI_Score'] = gdf['RPL_THEMES'].replace(-999, np.nan)\n",
    "    else:\n",
    "        print(\" SVI column missing, creating dummy for demo.\")\n",
    "        gdf['SVI_Score'] = np.random.rand(len(gdf))\n",
    "        \n",
    "    # Map 1: Social Vulnerability Index\n",
    "    create_publication_map(\n",
    "        gdf, \n",
    "        column='SVI_Score', \n",
    "        title=\"Input Variable: Social Vulnerability Index (SVI)\\nPhiladelphia (2020)\", \n",
    "        output_path=DIRS[\"process\"] / \"02_process_SVI_distribution.png\",\n",
    "        cmap='OrRd', # Orange-Red for danger/vulnerability\n",
    "        scheme='Quantiles'\n",
    "    )\n",
    "    \n",
    "    # Map 2: Population Density (Calculated in Meters)\n",
    "    # Area is in Sq Meters. Convert to Sq Km -> Area / 10^6\n",
    "    gdf['pop_density_sqkm'] = gdf['population'] / (gdf.geometry.area / 1_000_000)\n",
    "    \n",
    "    create_publication_map(\n",
    "        gdf,\n",
    "        column='pop_density_sqkm',\n",
    "        title=\"Input Variable: Population Density\\n(People per Sq. Km)\",\n",
    "        output_path=DIRS[\"process\"] / \"02_process_pop_density.png\",\n",
    "        cmap='Blues',\n",
    "        scheme='FisherJenks' # Good for density with outliers\n",
    "    )\n",
    "\n",
    "module_2_visualize_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191b350-318e-4f7f-b6eb-b4aef0a4432a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "251861c5-4134-495d-a126-cb7b8e52edc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Module 3: Generating All Final Deliverables (Fixed Scale & Transparency)...\n",
      "   ... 1/2 Generating Static Equity Gap Map (PNG)\n",
      "       Saved: 03_final_equity_gap_map_optimized.png\n",
      "   ... 2/2 Generating Interactive Map (HTML)\n",
      "       Saved: 04_final_recommendation_map_interactive.html\n",
      "       Open this file to see transparent -999 areas.\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "# ---------------------------------------------------------\n",
    "# OPTIMIZED MODULE 3: FINAL VISUALIZATION SUITE (TRANSPARENT NODATA)\n",
    "# ---------------------------------------------------------\n",
    "def module_3_complete_suite():\n",
    "    print(\" Module 3: Generating All Final Deliverables (Fixed Scale & Transparency)...\")\n",
    "    \n",
    "    # Define Paths\n",
    "    res_path = BASE_DIR / \"results\" / \"final_E2SFCA_results.geojson\"\n",
    "    rec_path = BASE_DIR / \"results\" / \"recommended_new_sites.geojson\"\n",
    "    \n",
    "    if not res_path.exists():\n",
    "        print(\" Data not found. Please run the analysis module first.\")\n",
    "        return\n",
    "\n",
    "    # Load Data\n",
    "    gdf_res = gpd.read_file(res_path)\n",
    "    if rec_path.exists():\n",
    "        gdf_rec = gpd.read_file(rec_path)\n",
    "    else:\n",
    "        gdf_rec = None\n",
    "\n",
    "    # =========================================================\n",
    "    # PART 1: STATIC EQUITY GAP MAP (Refined PNG)\n",
    "    # =========================================================\n",
    "    print(\"   ... 1/2 Generating Static Equity Gap Map (PNG)\")\n",
    "    \n",
    "    gdf_static = gdf_res.to_crs(CRS_METRIC).copy()\n",
    "    \n",
    "    # Calculate Gap Percentage\n",
    "    access_all_safe = gdf_static['access_all'].replace(0, 0.0001)\n",
    "    gdf_static['equity_gap_pct'] = ((gdf_static['access_all'] - gdf_static['access_medicaid']) / access_all_safe) * 100\n",
    "    gdf_static['equity_gap_pct'] = gdf_static['equity_gap_pct'].clip(0, 100).fillna(0)\n",
    "    \n",
    "    # Reproject\n",
    "    gdf_plot = gdf_static.to_crs(CRS_VISUAL)\n",
    "    \n",
    "    # Check if data is too uniform\n",
    "    scheme = 'EqualInterval' if gdf_static['equity_gap_pct'].nunique() <= 1 else 'Quantiles'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    gdf_plot.plot(\n",
    "        column='equity_gap_pct',\n",
    "        ax=ax,\n",
    "        cmap='OrRd', \n",
    "        scheme=scheme,\n",
    "        k=5,\n",
    "        alpha=0.85,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.1,\n",
    "        legend=True,\n",
    "        legend_kwds={\n",
    "            'loc': 'upper right',\n",
    "            'title': 'Access Loss (%)',\n",
    "            'framealpha': 0.9,\n",
    "            'facecolor': 'white'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Clean Legend\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        for text in leg.get_texts():\n",
    "            try:\n",
    "                parts = text.get_text().replace('(', '').replace(']', '').replace('[', '').split(',')\n",
    "                if len(parts) == 2:\n",
    "                    text.set_text(f\"{float(parts[0]):.0f}% - {float(parts[1]):.0f}%\")\n",
    "            except: pass \n",
    "\n",
    "    try: ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    except: pass\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(\"The Medicaid Equity Gap\\n(% Access Lost Due to Insurance Barriers)\", fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    out_png = DIRS[\"final\"] / \"03_final_equity_gap_map_optimized.png\"\n",
    "    plt.savefig(out_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"       Saved: {out_png.name}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # PART 2: INTERACTIVE RECOMMENDATION MAP (HTML) - TRANSPARENT NODATA\n",
    "    # =========================================================\n",
    "    print(\"   ... 2/2 Generating Interactive Map (HTML)\")\n",
    "    \n",
    "    if gdf_rec is None:\n",
    "        return\n",
    "\n",
    "    # Reproject\n",
    "    gdf_res_web = gdf_res.to_crs(\"EPSG:4326\")\n",
    "    gdf_rec_web = gdf_rec.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Handle SVI Column\n",
    "    svi_col = 'SVI' if 'SVI' in gdf_res_web.columns else 'RPL_THEMES'\n",
    "    if svi_col not in gdf_res_web.columns:\n",
    "        gdf_res_web[svi_col] = 0.5 \n",
    "    \n",
    "    # --- KEY FIX: DATA CLEANING & TRANSPARENCY ---\n",
    "    # 1. Replace -999 with NaN so they are treated as missing\n",
    "    gdf_res_web[svi_col] = gdf_res_web[svi_col].replace(-999, np.nan)\n",
    "    \n",
    "    # Initialize Map\n",
    "    m = folium.Map(location=[39.9526, -75.1652], zoom_start=11, tiles=\"CartoDB positron\")\n",
    "\n",
    "    # Define bins to force valid range 0-1\n",
    "    bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "    # Add SVI Choropleth (Background)\n",
    "    folium.Choropleth(\n",
    "        geo_data=gdf_res_web,\n",
    "        name=\"Social Vulnerability (SVI)\",\n",
    "        data=gdf_res_web,\n",
    "        columns=['GEOID', svi_col],\n",
    "        key_on='feature.properties.GEOID',\n",
    "        fill_color='Purples',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.1,\n",
    "        # --- TRANSPARENCY FIX ---\n",
    "        nan_fill_opacity=0,    # Make missing values (NaN/-999) fully transparent\n",
    "        nan_fill_color='white', # Fallback (won't be seen if opacity is 0)\n",
    "        # ------------------------\n",
    "        legend_name='Social Vulnerability (0=Low, 1=High)',\n",
    "        bins=bins,\n",
    "        highlight=True\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add Tooltips\n",
    "    style_function = lambda x: {'fillColor': '#ffffff', 'color':'#000000', 'fillOpacity': 0.1, 'weight': 0.1}\n",
    "    highlight_function = lambda x: {'fillColor': '#000000', 'color':'#000000', 'fillOpacity': 0.50, 'weight': 0.1}\n",
    "    \n",
    "    hover_layer = folium.features.GeoJson(\n",
    "        gdf_res_web,\n",
    "        style_function=style_function,\n",
    "        control=False,\n",
    "        highlight_function=highlight_function,\n",
    "        tooltip=folium.features.GeoJsonTooltip(\n",
    "            fields=[svi_col, 'access_all'],\n",
    "            aliases=['SVI Score:', 'Access Score:'],\n",
    "            style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\")\n",
    "        )\n",
    "    )\n",
    "    m.add_child(hover_layer)\n",
    "\n",
    "    # Add Recommended Sites\n",
    "    for _, row in gdf_rec_web.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=folium.Popup(f\"<b>{row['suggestion']}</b><br>Optimized for High Equity Gain\", max_width=300),\n",
    "            tooltip=row['suggestion'],\n",
    "            icon=folium.Icon(color='red', icon='star', prefix='fa')\n",
    "        ).add_to(m)\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    out_html = DIRS[\"final\"] / \"04_final_recommendation_map_interactive.html\"\n",
    "    m.save(out_html)\n",
    "    print(f\"       Saved: {out_html.name}\")\n",
    "    print(\"       Open this file to see transparent -999 areas.\")\n",
    "\n",
    "# Run module 3\n",
    "module_3_complete_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b17c5-d1be-4f15-862f-9b705cea3a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "556fcb63-9b10-4eb0-9447-8d29574b258f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating Optimized Interactive Dashboard...\n",
      " Dynamic Scale Max - Equity Gap: 30.28%\n",
      " Dynamic Scale Max - Weighted Impact: 25.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.main: missing_color option not found for polygons plot with bokeh; similar options include: ['line_color', 'selection_color', 'muted_line_color']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.main: missing_color option not found for polygons plot with bokeh; similar options include: ['line_color', 'selection_color', 'muted_line_color']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|                                                               | 1/4 [00:01<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.main: missing_color option not found for polygons plot with bokeh; similar options include: ['line_color', 'selection_color', 'muted_line_color']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|                                          | 2/4 [00:02<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.main: missing_color option not found for polygons plot with bokeh; similar options include: ['line_color', 'selection_color', 'muted_line_color']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|                     | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.main: missing_color option not found for polygons plot with bokeh; similar options include: ['line_color', 'selection_color', 'muted_line_color']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: figure(id='d2aed220-dbc3-4fb0-a0e8-41ab2d6becb8', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: Column(id='5675d8a6-7c62-4356-90cf-84f73a1421ae', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dashboard saved to: results\\03_final_deliverables\\index.html\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(r\".\")\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# FIX: Simplified path to avoid \"results/results\" duplication\n",
    "HTML_OUT = RESULTS_DIR / \"03_final_deliverables\" / \"index.html\"\n",
    "def generate_web_dashboard():\n",
    "    print(\" Generating Optimized Interactive Dashboard...\")\n",
    "    \n",
    "    res_path = RESULTS_DIR / \"final_E2SFCA_results.geojson\"\n",
    "    if not res_path.exists():\n",
    "        print(\" Results file not found.\")\n",
    "        return\n",
    "\n",
    "    gdf = gpd.read_file(res_path).to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # 1. Clean SVI Data (Replace -999 with NaN for transparency)\n",
    "    if 'RPL_THEMES' in gdf.columns:\n",
    "        gdf['SVI'] = gdf['RPL_THEMES'].replace(-999, np.nan)\n",
    "    else:\n",
    "        gdf['SVI'] = np.nan\n",
    "\n",
    "    # 2. Calculate Equity Gap (% Access Lost)\n",
    "    # Logic: (Access All - Access Medicaid) / Access All\n",
    "    gdf['Equity_Gap'] = (\n",
    "        ((gdf['access_all'] - gdf['access_medicaid']) / gdf['access_all'].replace(0, 0.0001)) * 100\n",
    "    ).clip(0, 100).fillna(0)\n",
    "\n",
    "    # 3. Calculate \"Weighted Impact\" (New Metric)\n",
    "    # Logic: Equity Gap * SVI. \n",
    "    # Highlights areas that lose access AND are socially vulnerable.\n",
    "    gdf['Weighted_Impact'] = gdf['Equity_Gap'] * gdf['SVI'].fillna(0)\n",
    "\n",
    "    gdf['Access_Score'] = gdf['access_medicaid']\n",
    "\n",
    "    # ---------------- DYNAMIC SCALING LOGIC ----------------\n",
    "    # Calculate the 95th percentile to ignore extreme outliers.\n",
    "    # This ensures the map colors aren't washed out by one tiny area with 100% loss.\n",
    "    gap_max = gdf['Equity_Gap'].quantile(0.95)\n",
    "    impact_max = gdf['Weighted_Impact'].quantile(0.95)\n",
    "    \n",
    "    # Ensure min threshold to prevent crashes if all data is 0\n",
    "    if gap_max < 1: gap_max = 1.0 \n",
    "    if impact_max < 0.1: impact_max = 0.1\n",
    "\n",
    "    print(f\" Dynamic Scale Max - Equity Gap: {gap_max:.2f}%\")\n",
    "    print(f\" Dynamic Scale Max - Weighted Impact: {impact_max:.2f}\")\n",
    "\n",
    "    # ---------------- VISUALIZATION ----------------\n",
    "    def get_map(metric):\n",
    "        # Dynamic Configuration Dictionary\n",
    "        configs = {\n",
    "            'SVI': {\n",
    "                'cmap': 'OrRd', \n",
    "                'title': 'Social Vulnerability (SVI)', \n",
    "                'clim': (0, 1)\n",
    "            },\n",
    "            'Equity_Gap': {\n",
    "                'cmap': 'Plasma', \n",
    "                'title': f'Equity Gap (% Access Lost) [Scale: 0 - {gap_max:.1f}%]', \n",
    "                'clim': (0, gap_max) # <--- Dynamic Scale used here\n",
    "            },\n",
    "            'Weighted_Impact': {\n",
    "                'cmap': 'Inferno', \n",
    "                'title': 'Priority Index (Gap x SVI)', \n",
    "                'clim': (0, impact_max)\n",
    "            },\n",
    "            'Access_Score': {\n",
    "                'cmap': 'Viridis', \n",
    "                'title': 'Raw Accessibility Score', \n",
    "                'clim': None # Auto-range\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        c = configs[metric]\n",
    "        clim_args = {}\n",
    "        if c['clim']:\n",
    "            clim_args['clim'] = c['clim']\n",
    "\n",
    "        return gdf.hvplot.polygons(\n",
    "            c=metric,\n",
    "            cmap=c['cmap'],\n",
    "            title=c['title'],\n",
    "            geo=True,\n",
    "            tiles='CartoLight',\n",
    "            alpha=0.75,\n",
    "            hover_cols=['GEOID', 'SVI', 'Equity_Gap', 'Weighted_Impact', 'Access_Score'],\n",
    "            line_width=0.05,\n",
    "            line_color='white',\n",
    "            frame_height=600,\n",
    "            aspect='equal',\n",
    "            missing_color='rgba(0,0,0,0)', \n",
    "            **clim_args\n",
    "        )\n",
    "\n",
    "    # Widgets\n",
    "    metrics_list = ['Equity_Gap', 'Weighted_Impact', 'SVI', 'Access_Score']\n",
    "    select_widget = pn.widgets.Select(name='Select Metric:', options=metrics_list)\n",
    "    \n",
    "    desc = pn.pane.Markdown(\"\"\"\n",
    "    #  Philadelphia Healthcare Equity Explorer\n",
    "    **Thesis Project: Beyond Physical Distance**\n",
    "    \n",
    "    * **Equity Gap:** Percentage of access lost when relying solely on Medicaid facilities. (Scaled dynamically).\n",
    "    * **Priority Index:** Combines the Equity Gap with SVI. High values = Vulnerable areas losing significant access.\n",
    "    * **SVI:** Social Vulnerability Index.\n",
    "    \"\"\")\n",
    "    \n",
    "    dashboard = pn.Column(\n",
    "        desc,\n",
    "        select_widget,\n",
    "        pn.bind(get_map, metric=select_widget)\n",
    "    )\n",
    "    \n",
    "    dashboard.save(str(HTML_OUT), embed=True)\n",
    "    print(f\" Dashboard saved to: {HTML_OUT}\")\n",
    "    return dashboard\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_web_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b37e5d-10bb-4ded-af38-398ef0146c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64e1aa-b983-4af4-9d91-a079eeba2787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680628e-6999-4bb0-9f77-147c53b89c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5a640c3-c02d-4975-81a9-dda0e0f5c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Sensitivity Analysis (15, 20, 30 mins)...\n",
      "   ...Loading road network\n",
      "   ...Calculating OD Matrix\n",
      "   ...Processing 15 minute threshold\n",
      "   ...Processing 20 minute threshold\n",
      "   ...Processing 30 minute threshold\n",
      "   ...Identifying Medical Deserts\n",
      " Sensitivity results saved to: results\\sensitivity\\sensitivity_analysis.geojson\n"
     ]
    }
   ],
   "source": [
    "# ---------------- CONFIGURATION ----------------\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\"\n",
    "DATA_RAW = BASE_DIR / \"data\" / \"raw\"\n",
    "RESULTS_DIR = BASE_DIR / \"results/sensitivity/\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TARGET_CRS = \"EPSG:32129\"\n",
    "\n",
    "def gaussian_weight(t, t_0):\n",
    "    \"\"\"Calculates Gaussian weight based on dynamic threshold t_0.\"\"\"\n",
    "    if t > t_0: return 0\n",
    "    beta = - (t_0 ** 2) / np.log(0.01)\n",
    "    return np.exp(- (t ** 2) / beta)\n",
    "\n",
    "def run_sensitivity_analysis():\n",
    "    print(\" Starting Sensitivity Analysis (15, 20, 30 mins)...\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    tracts = gpd.read_file(DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\")\n",
    "    facilities = gpd.read_file(DATA_PROCESSED / \"facilities_with_buffer.geojson\")\n",
    "    \n",
    "    # Load Network\n",
    "    print(\"   ...Loading road network\")\n",
    "    G = ox.load_graphml(DATA_RAW / \"philly_drive_network.graphml\")\n",
    "    G = ox.project_graph(G, to_crs=TARGET_CRS)\n",
    "    G = ox.add_edge_speeds(G)\n",
    "    G = ox.add_edge_travel_times(G)\n",
    "\n",
    "    # 2. Calculate OD Matrix (Max cutoff 45 mins to cover all scenarios)\n",
    "    print(\"   ...Calculating OD Matrix\")\n",
    "    tract_centroids = tracts.geometry.centroid\n",
    "    facility_points = facilities.geometry\n",
    "    \n",
    "    orig_nodes = ox.nearest_nodes(G, X=tract_centroids.x, Y=tract_centroids.y)\n",
    "    dest_nodes = ox.nearest_nodes(G, X=facility_points.x, Y=facility_points.y)\n",
    "    \n",
    "    unique_origs = list(set(orig_nodes))\n",
    "    od_times = {}\n",
    "    \n",
    "    for o_node in unique_origs:\n",
    "        lengths = nx.single_source_dijkstra_path_length(\n",
    "            G, o_node, weight='travel_time', cutoff=45*60\n",
    "        )\n",
    "        od_times[o_node] = lengths\n",
    "\n",
    "    # 3. Loop through thresholds\n",
    "    thresholds = [15, 20, 30]\n",
    "    \n",
    "    # Determine columns\n",
    "    pop_col = 'population' if 'population' in tracts.columns else 'E_TOTPOP'\n",
    "    if pop_col not in tracts.columns: tracts['dummy_pop'] = 1000; pop_col = 'dummy_pop'\n",
    "    \n",
    "    bed_col = 'BEDS'\n",
    "    if bed_col not in facilities.columns: facilities[bed_col] = 1.0\n",
    "\n",
    "    for t_threshold in thresholds:\n",
    "        print(f\"   ...Processing {t_threshold} minute threshold\")\n",
    "        \n",
    "        # --- Step 1: Supply-to-Demand Ratio (R_j) ---\n",
    "        r_j_list = []\n",
    "        for idx, row in facilities.iterrows():\n",
    "            f_node = dest_nodes[idx]\n",
    "            cap = float(row[bed_col])\n",
    "            \n",
    "            weighted_pop = 0\n",
    "            for i, tract in tracts.iterrows():\n",
    "                t_node = orig_nodes[i]\n",
    "                if t_node in od_times and f_node in od_times[t_node]:\n",
    "                    time_min = od_times[t_node][f_node] / 60\n",
    "                    weighted_pop += tract[pop_col] * gaussian_weight(time_min, t_threshold)\n",
    "            \n",
    "            r_j_list.append(cap / weighted_pop if weighted_pop > 0 else 0)\n",
    "        \n",
    "        # --- Step 2: Accessibility Index (A_i) ---\n",
    "        ai_list = []\n",
    "        for i, tract in tracts.iterrows():\n",
    "            t_node = orig_nodes[i]\n",
    "            sum_r = 0\n",
    "            for idx, row in facilities.iterrows():\n",
    "                f_node = dest_nodes[idx]\n",
    "                if t_node in od_times and f_node in od_times[t_node]:\n",
    "                    time_min = od_times[t_node][f_node] / 60\n",
    "                    # Use R_j calculated above\n",
    "                    sum_r += r_j_list[idx] * gaussian_weight(time_min, t_threshold)\n",
    "            ai_list.append(sum_r * 1000)\n",
    "            \n",
    "        tracts[f'access_{t_threshold}min'] = ai_list\n",
    "\n",
    "    # 4. Identify Medical Deserts (Binary Definition)\n",
    "    # Definition: Access score in bottom 20% AND Time to nearest > 30 mins\n",
    "    print(\"   ...Identifying Medical Deserts\")\n",
    "    \n",
    "    # Calculate nearest time\n",
    "    min_times = []\n",
    "    for i, tract in tracts.iterrows():\n",
    "        t_node = orig_nodes[i]\n",
    "        min_t = 9999\n",
    "        for idx, row in facilities.iterrows():\n",
    "            f_node = dest_nodes[idx]\n",
    "            if t_node in od_times and f_node in od_times[t_node]:\n",
    "                time_min = od_times[t_node][f_node] / 60\n",
    "                if time_min < min_t: min_t = time_min\n",
    "        min_times.append(min_t)\n",
    "    \n",
    "    tracts['nearest_time'] = min_times\n",
    "    \n",
    "    # Logic\n",
    "    score_cutoff = tracts['access_30min'].quantile(0.20)\n",
    "    tracts['is_desert'] = (tracts['access_30min'] < score_cutoff) | (tracts['nearest_time'] > 30)\n",
    "    \n",
    "    # 5. Save\n",
    "    out_path = RESULTS_DIR / \"sensitivity_analysis.geojson\"\n",
    "    tracts.to_file(out_path, driver=\"GeoJSON\")\n",
    "    print(f\" Sensitivity results saved to: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982cd67-c253-481e-8917-7bc84a185f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b557b3-35a4-4247-bab4-5e2e2ae1409a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeaac36-ca3d-4681-b435-d8e14e4bcaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f062518c-ad3d-4356-bb88-2a4779fef70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running K-Means Clustering & Statistical Reporting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Clustered data saved to: results\\cluster\\tracts_clustered.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14175\\AppData\\Local\\Temp\\ipykernel_6864\\1608935071.py:116: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Charts saved to: results\\cluster\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "BASE_DIR = Path(\".\")\n",
    "INPUT_FILE = BASE_DIR / \"results\" / \"final_E2SFCA_results.geojson\"\n",
    "OUTPUT_DIR = BASE_DIR / \"results/cluster\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "def get_cluster_label(row, stats):\n",
    "    \"\"\"\n",
    "    Helper function to generate descriptive English labels \n",
    "    based on the cluster's average statistics.\n",
    "    \"\"\"\n",
    "    cid = row['Cluster_ID']\n",
    "    avg_svi = stats.loc[cid, 'SVI_Clean']\n",
    "    avg_access = stats.loc[cid, 'access_all']\n",
    "    \n",
    "    # Define thresholds (you can adjust these based on your specific data distribution)\n",
    "    # Using the global mean of the cluster centers to decide High/Low\n",
    "    svi_threshold = stats['SVI_Clean'].mean()\n",
    "    access_threshold = stats['access_all'].mean()\n",
    "\n",
    "    svi_label = \"High Vuln\" if avg_svi > svi_threshold else \"Low Vuln\"\n",
    "    \n",
    "    # Creating descriptive Groups\n",
    "    if avg_svi < 0.6: # Based on your plot, the split is clearly around 0.6\n",
    "        return \"Privileged (Low SVI, High Access)\"\n",
    "    else:\n",
    "        # For High SVI, we have 3 levels of access\n",
    "        if avg_access > 10.5:\n",
    "             return \"Supported (High SVI, High Access)\"\n",
    "        elif avg_access < 9.0:\n",
    "             return \"Critical Desert (High SVI, Low Access)\"\n",
    "        else:\n",
    "             return \"Moderate Access (High SVI)\"\n",
    "\n",
    "def run_clustering_and_stats():\n",
    "    print(\" Running K-Means Clustering & Statistical Reporting...\")\n",
    "    \n",
    "    if not INPUT_FILE.exists():\n",
    "        print(\" Input file not found. Run your main analysis first.\")\n",
    "        return\n",
    "\n",
    "    gdf = gpd.read_file(INPUT_FILE)\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    svi_col = 'RPL_THEMES' if 'RPL_THEMES' in gdf.columns else 'SVI'\n",
    "    if svi_col in gdf.columns:\n",
    "        gdf['SVI_Clean'] = gdf[svi_col].replace(-999, np.nan)\n",
    "        gdf['SVI_Clean'] = gdf['SVI_Clean'].fillna(gdf['SVI_Clean'].mean())\n",
    "    else:\n",
    "        gdf['SVI_Clean'] = 0.5\n",
    "        \n",
    "    gdf_clean = gdf.dropna(subset=['access_all', 'SVI_Clean'])\n",
    "    \n",
    "    # 2. K-Means Clustering\n",
    "    features = gdf_clean[['access_all', 'SVI_Clean']].copy()\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "    gdf_clean['Cluster_ID'] = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    # --- NEW STEP: ASSIGN ENGLISH NAMES ---\n",
    "    # Calculate stats per cluster to determine what they represent\n",
    "    cluster_stats = gdf_clean.groupby('Cluster_ID')[['access_all', 'SVI_Clean']].mean()\n",
    "    \n",
    "    # Apply the naming function\n",
    "    gdf_clean['Cluster_Label'] = gdf_clean.apply(\n",
    "        lambda row: get_cluster_label(row, cluster_stats), axis=1\n",
    "    )\n",
    "    \n",
    "    # Save clustered data\n",
    "    cluster_out = OUTPUT_DIR / \"tracts_clustered.geojson\"\n",
    "    gdf_clean.to_file(cluster_out, driver=\"GeoJSON\")\n",
    "    print(f\"     Clustered data saved to: {cluster_out}\")\n",
    "\n",
    "    # 3. Generate Summary CSV\n",
    "    summary = gdf_clean.groupby('Cluster_Label')[['access_all', 'SVI_Clean']].mean()\n",
    "    summary_path = OUTPUT_DIR / \"cluster_summary.csv\"\n",
    "    summary.to_csv(summary_path)\n",
    "      \n",
    "    # Define a custom color palette logic if needed, or stick to viridis\n",
    "    \n",
    "    # A. Scatter Plot\n",
    "    plt.figure(figsize=(12, 7)) # Made it slightly wider for the legend\n",
    "    sns.scatterplot(\n",
    "        data=gdf_clean, \n",
    "        x='SVI_Clean', \n",
    "        y='access_all', \n",
    "        hue='Cluster_Label', # <--- USE THE LABEL COLUMN\n",
    "        palette='viridis',\n",
    "        s=60, alpha=0.8\n",
    "    )\n",
    "    plt.title(\"Cluster Analysis: Accessibility vs. Social Vulnerability\")\n",
    "    plt.xlabel(\"Social Vulnerability (SVI)\")\n",
    "    plt.ylabel(\"Accessibility Score (E2SFCA)\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Population Group') # Move legend outside\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"scatter_clusters_labeled.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # B. Box Plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.boxplot(\n",
    "        x='Cluster_Label', # <--- USE THE LABEL COLUMN\n",
    "        y='access_all', \n",
    "        data=gdf_clean, \n",
    "        palette='Set2'\n",
    "    )\n",
    "    plt.title(\"Accessibility Distribution by Population Group\")\n",
    "    plt.xlabel(\"Population Group\")\n",
    "    plt.xticks(rotation=15) # Rotate text so it fits\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"boxplot_clusters_labeled.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"     Charts saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_clustering_and_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3e3ec86-b4b8-4c50-98c2-3d03ae494a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating SVI Tertile Boxplot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14175\\AppData\\Local\\Temp\\ipykernel_6864\\423683479.py:57: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n",
      "D:\\Geospatial_Workspace\\geo310\\lib\\site-packages\\seaborn\\categorical.py:700: PendingDeprecationWarning: vert: bool will be deprecated in a future version. Use orientation: {'vertical', 'horizontal'} instead.\n",
      "  artists = ax.bxp(**boxplot_kws)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVI Tertile Boxplot saved to: results\\cluster\\boxplot_svi_tertiles.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "BASE_DIR = Path(\".\")\n",
    "INPUT_FILE = BASE_DIR / \"results/cluster/tracts_clustered_labeled.geojson\" # Uses the file we just made\n",
    "OUTPUT_DIR = BASE_DIR / \"results/cluster\"\n",
    "\n",
    "# Set style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "def generate_svi_tertile_boxplot():\n",
    "    print(\" Generating SVI Tertile Boxplot...\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    if not INPUT_FILE.exists():\n",
    "        print(f\" Input file not found: {INPUT_FILE}\")\n",
    "        return\n",
    "    \n",
    "    gdf = gpd.read_file(INPUT_FILE)\n",
    "    \n",
    "    # 2. Create 3 Groups (Tertiles) based on SVI\n",
    "    # We use quantiles (33% and 66%) to ensure equal sample sizes in each group\n",
    "    low_cutoff = gdf['SVI_Clean'].quantile(0.33)\n",
    "    high_cutoff = gdf['SVI_Clean'].quantile(0.66)\n",
    "\n",
    "    def classify_svi(svi_score):\n",
    "        if svi_score <= low_cutoff:\n",
    "            return \"Low Vulnerability\"\n",
    "        elif svi_score <= high_cutoff:\n",
    "            return \"Medium Vulnerability\"\n",
    "        else:\n",
    "            return \"High Vulnerability\"\n",
    "\n",
    "    gdf['SVI_Group'] = gdf['SVI_Clean'].apply(classify_svi)\n",
    "\n",
    "    # 3. Define Order and Colors\n",
    "    # Order for the X-axis\n",
    "    group_order = [\"Low Vulnerability\", \"Medium Vulnerability\", \"High Vulnerability\"]\n",
    "    \n",
    "    # Sequential Palette: Light Blue -> Medium Blue -> Dark Blue\n",
    "    # This visually communicates \"Increasing Intensity\"\n",
    "    tertile_palette = {\n",
    "        \"Low Vulnerability\": \"#a6cee3\",    # Light Blue\n",
    "        \"Medium Vulnerability\": \"#1f78b4\", # Medium Blue\n",
    "        \"High Vulnerability\": \"#08306b\"    # Dark Navy\n",
    "    }\n",
    "\n",
    "    # 4. Generate Plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Create the boxplot\n",
    "    ax = sns.boxplot(\n",
    "        x='SVI_Group',\n",
    "        y='access_all',\n",
    "        data=gdf,\n",
    "        order=group_order,      # Force correct order\n",
    "        palette=tertile_palette,\n",
    "        width=0.5,              # Makes boxes slightly thinner (elegant look)\n",
    "        linewidth=1.5           # Thicker lines for the \"frame\" look\n",
    "    )\n",
    "\n",
    "    # 5. Styling\n",
    "    plt.title(\"Accessibility Distribution by Social Vulnerability Level\", fontsize=14, pad=15)\n",
    "    plt.xlabel(\"Social Vulnerability Group (Tertiles)\", fontsize=12)\n",
    "    plt.ylabel(\"Accessibility Score (E2SFCA)\", fontsize=12)\n",
    "    \n",
    "    # Add grid explicitly on Y axis for readability\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.xaxis.grid(False) # Turn off x-grid for cleaner look\n",
    "\n",
    "    # Save\n",
    "    out_path = OUTPUT_DIR / \"boxplot_svi_tertiles.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"     SVI Tertile Boxplot saved to: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_svi_tertile_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbba53d-10ae-4284-a771-12deb14cb00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ce5aaa1-36b6-4193-a276-899321bd800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating Map with FORCED LEGEND...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14175\\AppData\\Local\\Temp\\ipykernel_6864\\62653639.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  gdf_web['SVI'].fillna(gdf_web['SVI'].median(), inplace=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_time_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m INPUT_FILE\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    102\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(INPUT_FILE)\n\u001b[1;32m--> 103\u001b[0m     \u001b[43mrun_ultimate_legend_fix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Done! Check output in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[34], line 19\u001b[0m, in \u001b[0;36mrun_ultimate_legend_fix\u001b[1;34m(gdf)\u001b[0m\n\u001b[0;32m     17\u001b[0m time_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest_time\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m gdf_web\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 19\u001b[0m     time_col \u001b[38;5;241m=\u001b[39m \u001b[43mfind_time_column\u001b[49m(gdf_web)\n\u001b[0;32m     21\u001b[0m max_time \u001b[38;5;241m=\u001b[39m gdf_web[time_col]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(max_time): max_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_time_column' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# MAP 3: ULTIMATE LEGEND FIX (Force-Render Mode)\n",
    "# ---------------------------------------------------------\n",
    "def run_ultimate_legend_fix(gdf):\n",
    "    print(\" Generating Map with FORCED LEGEND...\")\n",
    "    \n",
    "    # Reproject\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    # --- 1. DATA PREP ---\n",
    "    if 'RPL_THEMES' in gdf_web.columns:\n",
    "        gdf_web['SVI'] = gdf_web['RPL_THEMES'].replace(-999, np.nan)\n",
    "    else:\n",
    "        gdf_web['SVI'] = np.nan\n",
    "    gdf_web['SVI'].fillna(gdf_web['SVI'].median(), inplace=True)\n",
    "\n",
    "    time_col = 'nearest_time'\n",
    "    if time_col not in gdf_web.columns:\n",
    "        time_col = find_time_column(gdf_web)\n",
    "    \n",
    "    max_time = gdf_web[time_col].max()\n",
    "    if pd.isna(max_time): max_time = 60\n",
    "    gdf_web[time_col].fillna(max_time, inplace=True)\n",
    "\n",
    "    # --- 2. THRESHOLDS ---\n",
    "    svi_threshold = gdf_web['SVI'].median()\n",
    "    time_threshold = gdf_web[time_col].median()\n",
    "\n",
    "    # --- 3. CATEGORIES ---\n",
    "    def get_category(row):\n",
    "        is_high_svi = row['SVI'] >= svi_threshold\n",
    "        is_high_acc = row[time_col] < time_threshold # Low time = High Access\n",
    "        \n",
    "        if is_high_svi and is_high_acc:\n",
    "            return \"High SVI / High Access\"\n",
    "        elif is_high_svi and not is_high_acc:\n",
    "            return \"High SVI / Low Access\"\n",
    "        elif not is_high_svi and is_high_acc:\n",
    "            return \"Low SVI / High Access\"\n",
    "        else:\n",
    "            return \"Low SVI / Low Access\"\n",
    "\n",
    "    gdf_web['category_label'] = gdf_web.apply(get_category, axis=1)\n",
    "\n",
    "    # --- 4. COLORS (Professional PiYG) ---\n",
    "    custom_colors = {\n",
    "        \"High SVI / Low Access\":  \"#e95e4f\", # Magenta (Critical)\n",
    "        \"High SVI / High Access\": \"#48a2de\", # Pink\n",
    "        \"Low SVI / High Access\":  \"#43d17f\", # Dark Green (Ideal)\n",
    "        \"Low SVI / Low Access\":   \"#f4a629\"  # Light Green\n",
    "    }\n",
    "    \n",
    "    # --- 5. PLOTTING ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 12)) \n",
    "    \n",
    "    # A. Plot the actual map data\n",
    "    for cat, color in custom_colors.items():\n",
    "        subset = gdf_web[gdf_web['category_label'] == cat]\n",
    "        if len(subset) > 0:\n",
    "            subset.plot(ax=ax, color=color, edgecolor='white', linewidth=0.05)\n",
    "    \n",
    "    # B. FORCE THE LEGEND (The \"Invisible Dot\" Trick)\n",
    "    # We create empty scatter points for EVERY category just for the legend\n",
    "    # This guarantees the legend box is full, even if data is missing or weird.\n",
    "    legend_elements = []\n",
    "    for cat, color in custom_colors.items():\n",
    "        legend_elements.append(\n",
    "            plt.Line2D([0], [0], marker='s', color='w', label=cat,\n",
    "                       markerfacecolor=color, markersize=12)\n",
    "        )\n",
    "\n",
    "    add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    add_north_arrow(ax)\n",
    "    add_scale_bar(ax)\n",
    "    \n",
    "    ax.set_title(\"Neighborhood Typologies: Vulnerability vs. Access\\n(Bivariate Classification)\", \n",
    "                 fontweight='bold', fontsize=18)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # --- C. RENDER LEGEND (Top Left - Safe Zone) ---\n",
    "    ax.legend(\n",
    "        handles=legend_elements,\n",
    "        loc='upper left',          # Safer than outside\n",
    "        bbox_to_anchor=(0.02, 0.98), # Fine tune inside the box\n",
    "        title=\"Neighborhood Type\",\n",
    "        title_fontsize=12,\n",
    "        fontsize=10,\n",
    "        frameon=True,\n",
    "        facecolor='white',\n",
    "        edgecolor='black',\n",
    "        framealpha=1\n",
    "    )\n",
    "    \n",
    "    outfile = OUTPUT_DIR / \"03_typologies_legend_forced.png\"\n",
    "    plt.savefig(outfile, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"    Map SAVED (Legend Guaranteed) to: {outfile}\")\n",
    "\n",
    "# --- EXECUTE ---\n",
    "if __name__ == \"__main__\":\n",
    "    if INPUT_FILE.exists():\n",
    "        gdf = gpd.read_file(INPUT_FILE)\n",
    "        run_ultimate_legend_fix(gdf)\n",
    "        print(f\"\\n Done! Check output in: {OUTPUT_DIR}\")\n",
    "    else:\n",
    "        print(\" Error: Input file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81517e8c-1fcb-4eb8-8c64-120a203bb8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f2f3d8d-f865-4eb9-8646-b48a6752b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Data...\n",
      "  Loading Graph...\n",
      "  Calculating OD Matrix (Dijkstra)...\n",
      " Running 2SFCA Sensitivity (15min vs 30min)...\n",
      "   ...Processing 15 min Catchment\n",
      "   ...Processing 30 min Catchment\n",
      " Generating Professional Map...\n",
      "    Min Diff: nan\n",
      "    Max Diff: nan\n",
      "    Map saved to: project_outputs_optimized\\04_sensitivity_difference_professional.png\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\"\n",
    "DATA_RAW = BASE_DIR / \"data\" / \"raw\"\n",
    "OUTPUT_DIR = BASE_DIR / \"project_outputs_optimized\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_CRS = \"EPSG:32129\"\n",
    "plt.rcParams.update({\"font.family\": \"sans-serif\", \"figure.dpi\": 300})\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. YOUR ORIGINAL DATA GENERATION LOGIC (Restored)\n",
    "# ---------------------------------------------------------\n",
    "def load_data_optimized():\n",
    "    print(\" Loading Data...\")\n",
    "    tracts_path = DATA_PROCESSED / \"tracts_pop_svi_projected.geojson\"\n",
    "    if not tracts_path.exists():\n",
    "        tracts_path = DATA_PROCESSED / \"tracts_svi_projected.geojson\"\n",
    "    \n",
    "    gdf_tracts = gpd.read_file(tracts_path).to_crs(TARGET_CRS)\n",
    "    \n",
    "    buffer_fac_path = DATA_PROCESSED / \"facilities_with_buffer.geojson\"\n",
    "    if not buffer_fac_path.exists():\n",
    "        buffer_fac_path = DATA_PROCESSED / \"facilities_projected.geojson\"\n",
    "        \n",
    "    gdf_facilities = gpd.read_file(buffer_fac_path).to_crs(TARGET_CRS)\n",
    "    \n",
    "    # Ensure columns exist\n",
    "    if 'BEDS' not in gdf_facilities.columns: gdf_facilities['BEDS'] = 100\n",
    "    if 'population' not in gdf_tracts.columns: gdf_tracts['population'] = 1000\n",
    "        \n",
    "    return gdf_tracts, gdf_facilities\n",
    "\n",
    "def calculate_od_matrix(G, tracts, facilities):\n",
    "    print(\"  Calculating OD Matrix (Dijkstra)...\")\n",
    "    orig_nodes = ox.nearest_nodes(G, X=tracts.geometry.centroid.x, Y=tracts.geometry.centroid.y)\n",
    "    dest_nodes = ox.nearest_nodes(G, X=facilities.geometry.x, Y=facilities.geometry.y)\n",
    "    \n",
    "    unique_origs = list(set(orig_nodes))\n",
    "    od_times = {}\n",
    "    \n",
    "    # Cutoff 45 min\n",
    "    for o_node in unique_origs:\n",
    "        try:\n",
    "            lengths = nx.single_source_dijkstra_path_length(G, o_node, weight='travel_time', cutoff=45*60)\n",
    "            od_times[o_node] = lengths\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return orig_nodes, dest_nodes, od_times\n",
    "\n",
    "def run_2sfca_sensitivity(tracts, facilities, orig_nodes, dest_nodes, od_times):\n",
    "    print(\" Running 2SFCA Sensitivity (15min vs 30min)...\")\n",
    "    df_res = tracts.copy()\n",
    "    \n",
    "    for time_cutoff in [15, 30]:\n",
    "        print(f\"   ...Processing {time_cutoff} min Catchment\")\n",
    "        col_name = f'access_{time_cutoff}min'\n",
    "        \n",
    "        # Step 1: R_j\n",
    "        r_j_list = []\n",
    "        for j, fac in facilities.iterrows():\n",
    "            f_node = dest_nodes[j]\n",
    "            cap = fac['BEDS']\n",
    "            served_pop = 0\n",
    "            \n",
    "            for i, tract in tracts.iterrows():\n",
    "                t_node = orig_nodes[i]\n",
    "                if t_node in od_times and f_node in od_times[t_node]:\n",
    "                    time_min = od_times[t_node][f_node] / 60\n",
    "                    if time_min <= time_cutoff:\n",
    "                        served_pop += tract['population']\n",
    "            \n",
    "            r_j_list.append(cap / served_pop if served_pop > 0 else 0)\n",
    "        \n",
    "        facilities[f'R_{time_cutoff}'] = r_j_list\n",
    "        \n",
    "        # Step 2: A_i\n",
    "        a_i_list = []\n",
    "        for i, tract in tracts.iterrows():\n",
    "            t_node = orig_nodes[i]\n",
    "            sum_r = 0\n",
    "            for j, fac in facilities.iterrows():\n",
    "                f_node = dest_nodes[j]\n",
    "                if t_node in od_times and f_node in od_times[t_node]:\n",
    "                    time_min = od_times[t_node][f_node] / 60\n",
    "                    if time_min <= time_cutoff:\n",
    "                        sum_r += fac[f'R_{time_cutoff}']\n",
    "            a_i_list.append(sum_r * 1000)\n",
    "            \n",
    "        df_res[col_name] = a_i_list\n",
    "        \n",
    "    return df_res\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. PROFESSIONAL PLOTTING LOGIC (Applied to Memory Data)\n",
    "# ---------------------------------------------------------\n",
    "def plot_professional_map(gdf):\n",
    "    print(\" Generating Professional Map...\")\n",
    "    \n",
    "    # Reproject\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    \n",
    "    # Calculate Diff\n",
    "    gdf_web['access_diff'] = gdf_web['access_30min'] - gdf_web['access_15min']\n",
    "    \n",
    "    # DEBUG PRINT\n",
    "    print(f\"    Min Diff: {gdf_web['access_diff'].min():.4f}\")\n",
    "    print(f\"    Max Diff: {gdf_web['access_diff'].max():.4f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Plot Magma\n",
    "    try:\n",
    "        gdf_web.plot(\n",
    "            column='access_diff',\n",
    "            ax=ax,\n",
    "            cmap='magma',\n",
    "            scheme='quantiles',\n",
    "            k=5,\n",
    "            alpha=0.9,\n",
    "            edgecolor='white',\n",
    "            linewidth=0.05\n",
    "        )\n",
    "    except:\n",
    "        gdf_web.plot(column='access_diff', ax=ax, cmap='magma', alpha=0.9)\n",
    "\n",
    "    # Styling\n",
    "    try:\n",
    "        ctx.add_basemap(ax, crs=3857, source=ctx.providers.CartoDB.Positron, alpha=0.6)\n",
    "    except: pass\n",
    "\n",
    "    # North Arrow\n",
    "    x, y, arrow_length = 0.05, 0.95, 0.1\n",
    "    ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "                arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "                ha='center', va='center', fontsize=12, xycoords=ax.transAxes)\n",
    "\n",
    "    # Scale Bar\n",
    "    ax.add_artist(ScaleBar(1, location='lower left', box_alpha=0.5))\n",
    "\n",
    "    ax.set_title(\"Sensitivity Analysis: Access Gain\\n(Impact of Increasing Catchment from 15 to 30 min)\", \n",
    "                 fontweight='bold', fontsize=16)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Force Legend\n",
    "    import matplotlib.lines as mlines\n",
    "    cmap = plt.cm.magma\n",
    "    colors = [cmap(i) for i in [0.0, 0.25, 0.5, 0.75, 1.0]]\n",
    "    labels = [\"Low Gain\", \"Mod-Low\", \"Moderate\", \"Mod-High\", \"High Gain\"]\n",
    "    handles = [mlines.Line2D([], [], color=c, marker='s', linestyle='None', \n",
    "                            markersize=10, label=l) for c, l in zip(colors, labels)]\n",
    "\n",
    "    ax.legend(handles=handles, loc='lower right', title=\"Score Increase\", \n",
    "              frameon=True, framealpha=1, edgecolor='black')\n",
    "\n",
    "    out_file = OUTPUT_DIR / \"04_sensitivity_difference_professional.png\"\n",
    "    plt.savefig(out_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"    Map saved to: {out_file}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. MAIN EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Geometries\n",
    "    gdf_tracts, gdf_facilities = load_data_optimized()\n",
    "    \n",
    "    # 2. Load Network\n",
    "    graph_path = DATA_RAW / \"philly_drive_network.graphml\"\n",
    "    if graph_path.exists():\n",
    "        print(\"  Loading Graph...\")\n",
    "        G = ox.load_graphml(graph_path)\n",
    "        G = ox.project_graph(G, to_crs=TARGET_CRS)\n",
    "        G = ox.add_edge_speeds(G)\n",
    "        G = ox.add_edge_travel_times(G)\n",
    "        \n",
    "        # 3. Calculate Logic (Using your original functions)\n",
    "        orig_nodes, dest_nodes, od_times = calculate_od_matrix(G, gdf_tracts, gdf_facilities)\n",
    "        final_gdf = run_2sfca_sensitivity(gdf_tracts, gdf_facilities, orig_nodes, dest_nodes, od_times)\n",
    "        \n",
    "        # 4. Plot Directly\n",
    "        plot_professional_map(final_gdf)\n",
    "    else:\n",
    "        print(\" Error: Graph file missing. Cannot run calculation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7656a3-5517-4d04-b390-0197c4b3c02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813779c7-b595-4c73-8579-7a574946c62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68b253-e91b-4a04-b8cc-35dff98f02e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724689c-2972-44bb-81fc-eb21f58bc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdefef8-c344-4803-bed6-3b456003d168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9672f2-b934-4d9e-8fbd-08d761488d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7dd266-8ee1-4658-afab-9ee35182c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        let retries = 0;\n",
       "        const open = () => {\n",
       "          if (comm.active) {\n",
       "            comm.open();\n",
       "          } else if (retries > 3) {\n",
       "            console.warn('Comm target never activated')\n",
       "          } else {\n",
       "            retries += 1\n",
       "            setTimeout(open, 500)\n",
       "          }\n",
       "        }\n",
       "        if (comm.active) {\n",
       "          comm.open();\n",
       "        } else {\n",
       "          setTimeout(open, 500)\n",
       "        }\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        })\n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='9be3ea97-2e55-45c5-b7b0-87c16a793b9d'>\n",
       "  <div id=\"dc751f82-6da9-4f71-af78-7a24a17bcfec\" data-root-id=\"9be3ea97-2e55-45c5-b7b0-87c16a793b9d\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"aa692486-c06e-4825-82fe-8790bc620f87\":{\"version\":\"3.8.0\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"b9af7240-97cf-414d-8906-eee0403e44ff\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"404b88f2-ee62-4d20-91f4-4107f17be3e3\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"9be3ea97-2e55-45c5-b7b0-87c16a793b9d\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"e2bf40cb-4bdd-465e-b7b0-ffe205c6afdd\",\"attributes\":{\"plot_id\":\"9be3ea97-2e55-45c5-b7b0-87c16a793b9d\",\"comm_id\":\"f3e9c071195e4b56abb19e42baeeb667\",\"client_comm_id\":\"7d82fc17ec584d9f901261753bdac26c\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"aa692486-c06e-4825-82fe-8790bc620f87\",\"roots\":{\"9be3ea97-2e55-45c5-b7b0-87c16a793b9d\":\"dc751f82-6da9-4f71-af78-7a24a17bcfec\"},\"root_ids\":[\"9be3ea97-2e55-45c5-b7b0-87c16a793b9d\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "9be3ea97-2e55-45c5-b7b0-87c16a793b9d"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.panel_extension: bokeh extension not recognized and will be skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = false;\n",
       "  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = true;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        let retries = 0;\n",
       "        const open = () => {\n",
       "          if (comm.active) {\n",
       "            comm.open();\n",
       "          } else if (retries > 3) {\n",
       "            console.warn('Comm target never activated')\n",
       "          } else {\n",
       "            retries += 1\n",
       "            setTimeout(open, 500)\n",
       "          }\n",
       "        }\n",
       "        if (comm.active) {\n",
       "          comm.open();\n",
       "        } else {\n",
       "          setTimeout(open, 500)\n",
       "        }\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        })\n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for interactive map...\n",
      "Assembling final dashboard layout...\n",
      "Exporting website to docs\\index.html...\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: figure(id='e9329f0f-4c47-45a7-91ac-4b8e2e3208a9', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1005 (FIXED_SIZING_MODE): 'fixed' sizing mode requires width and height to be set: Column(id='c86ac8f6-2413-467b-a400-114ce31b5189', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: The website has been generated in the 'docs' folder.\n"
     ]
    }
   ],
   "source": [
    "import panel as pn\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize Panel extension\n",
    "pn.extension('bokeh')\n",
    "\n",
    "# =========================================================\n",
    "# 1. FILE PATH CONFIGURATION\n",
    "# =========================================================\n",
    "# Define base paths based on your provided structure\n",
    "BASE_DIR = Path(\".\")\n",
    "\n",
    "# Image Paths\n",
    "# Ensure these match your folder structure exactly\n",
    "IMG_EDGE_EFFECT = \"results/01_missteps_edge_effects/01_error_edge_effect_demonstration_fixed.png\"\n",
    "IMG_POP = \"results/02_intermediate_process/02_process_pop_density.png\"\n",
    "IMG_SVI = \"results/02_intermediate_process/02_process_SVI_distribution.png\"\n",
    "IMG_STATIC_MAP = \"results/03_final_deliverables/03_final_equity_gap_map_optimized.png\"\n",
    "IMG_SCATTER = \"results/cluster/scatter_high_contrast.png\"\n",
    "IMG_BOXPLOT = \"results/cluster/boxplot_high_contrast.png\"\n",
    "# Note: Ensure the folder 'final_deliverables' exists in your root, or adjust this path\n",
    "IMG_LEGEND = \"final_deliverables/publication_maps_v5/03_typologies_legend_forced.png\"\n",
    "\n",
    "# Data Path\n",
    "DATA_PATH = \"results/final_E2SFCA_results.geojson\"\n",
    "\n",
    "# =========================================================\n",
    "# 2. DATA LOADING AND PREPROCESSING\n",
    "# =========================================================\n",
    "print(\"Loading data for interactive map...\")\n",
    "gdf = gpd.read_file(DATA_PATH).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Clean SVI Data: Replace -999 with NaN for transparency\n",
    "if 'RPL_THEMES' in gdf.columns:\n",
    "    gdf['SVI'] = gdf['RPL_THEMES'].replace(-999, np.nan)\n",
    "else:\n",
    "    gdf['SVI'] = np.nan\n",
    "\n",
    "# Calculate Equity Gap (% Access Lost)\n",
    "# Formula: (Access All - Access Medicaid) / Access All\n",
    "gdf['Equity_Gap'] = (\n",
    "    ((gdf['access_all'] - gdf['access_medicaid']) / gdf['access_all'].replace(0, 0.0001)) * 100\n",
    ").clip(0, 100).fillna(0)\n",
    "\n",
    "# Calculate Priority Index (Weighted Impact)\n",
    "# Highlights areas that are both vulnerable AND losing access\n",
    "gdf['Weighted_Impact'] = gdf['Equity_Gap'] * gdf['SVI'].fillna(0)\n",
    "\n",
    "# Create a copy of the Medicaid access score for visualization\n",
    "gdf['Access_Score'] = gdf['access_medicaid']\n",
    "\n",
    "# Dynamic Scaling for Color Bars (95th percentile to handle outliers)\n",
    "gap_max = gdf['Equity_Gap'].quantile(0.95)\n",
    "if gap_max < 1: gap_max = 1.0\n",
    "impact_max = gdf['Weighted_Impact'].quantile(0.95)\n",
    "\n",
    "# =========================================================\n",
    "# 3. INTERACTIVE MAP LOGIC\n",
    "# =========================================================\n",
    "def get_interactive_map(metric):\n",
    "    # Configuration for each layer\n",
    "    configs = {\n",
    "        'SVI': {\n",
    "            'cmap': 'OrRd', \n",
    "            'title': 'Social Vulnerability Index (SVI)', \n",
    "            'clim': (0, 1)\n",
    "        },\n",
    "        'Equity_Gap': {\n",
    "            'cmap': 'Plasma', \n",
    "            'title': 'Equity Gap (% Access Lost due to Insurance)', \n",
    "            'clim': (0, gap_max)\n",
    "        },\n",
    "        'Weighted_Impact': {\n",
    "            'cmap': 'Inferno', \n",
    "            'title': 'Priority Index (Gap x SVI)', \n",
    "            'clim': (0, impact_max)\n",
    "        },\n",
    "        'Access_Score': {\n",
    "            'cmap': 'Viridis', \n",
    "            'title': 'Raw Accessibility Score (E2SFCA)', \n",
    "            'clim': None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    c = configs[metric]\n",
    "    clim_args = {'clim': c['clim']} if c['clim'] else {}\n",
    "    \n",
    "    # Generate the map using hvplot\n",
    "    return gdf.hvplot.polygons(\n",
    "        c=metric, \n",
    "        cmap=c['cmap'], \n",
    "        title=c['title'],\n",
    "        geo=True, \n",
    "        tiles='CartoLight', \n",
    "        alpha=0.7,\n",
    "        hover_cols=['GEOID', 'SVI', 'Equity_Gap', 'Weighted_Impact', 'Access_Score'],\n",
    "        line_width=0.05, \n",
    "        line_color='white',\n",
    "        frame_height=600, \n",
    "        aspect='equal',\n",
    "        colorbar=True,\n",
    "        **clim_args\n",
    "    )\n",
    "\n",
    "# Create the Dropdown Widget\n",
    "select_widget = pn.widgets.Select(\n",
    "    name='Select Analytical Layer:', \n",
    "    options=['Equity_Gap', 'Weighted_Impact', 'SVI', 'Access_Score']\n",
    ")\n",
    "\n",
    "# Bind the function to the widget\n",
    "interactive_map_pane = pn.Column(\n",
    "    select_widget, \n",
    "    pn.bind(get_interactive_map, metric=select_widget)\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 4. PROJECT NARRATIVE & ANALYSIS (EXPANDED)\n",
    "# =========================================================\n",
    "\n",
    "# CSS Styles for a professional academic look\n",
    "custom_style = {\n",
    "    'font-family': 'Helvetica, Arial, sans-serif',\n",
    "    'max-width': '1000px',\n",
    "    'margin': '0 auto',\n",
    "    'padding': '20px',\n",
    "    'line-height': '1.6',\n",
    "    'color': '#333333'\n",
    "}\n",
    "\n",
    "header_style = {\n",
    "    'color': '#2c3e50',\n",
    "    'border-bottom': '2px solid #eee',\n",
    "    'padding-bottom': '10px'\n",
    "}\n",
    "\n",
    "# --- Section 1: Introduction ---\n",
    "text_intro = \"\"\"\n",
    "# Philadelphia Healthcare Equity Analysis\n",
    "### Beyond Physical Distance: Measuring the Medicaid Access Gap\n",
    "\n",
    "**Executive Summary**\n",
    "Access to healthcare is often measured by physical proximity, but for low-income populations dependent on Medicaid, \"accessibility\" is legally and financially restricted. This project utilizes the **Enhanced Two-Step Floating Catchment Area (E2SFCA)** method to quantify the spatial disparity between *theoretical access* (all hospitals) and *actual access* (Medicaid-accepting facilities) in Philadelphia.\n",
    "\n",
    "**Research Question:**\n",
    "*How does limiting healthcare supply to Medicaid-accepting facilities alter the accessibility landscape for Philadelphia's most vulnerable neighborhoods?*\n",
    "\"\"\"\n",
    "\n",
    "# --- Section 2: Methodology ---\n",
    "text_method = \"\"\"\n",
    "## 1. Methodology & Data Sources\n",
    "\n",
    "To ensure a rigorous spatial analysis, this project integrated three distinct datasets:\n",
    "1.  **Supply:** Hospital locations from OpenDataPhilly, cross-referenced with CMS General Information data to verify Medicaid acceptance status.\n",
    "2.  **Demand:** Population data from the 2021 ACS (Census) and Social Vulnerability Index (SVI) scores from the CDC.\n",
    "3.  **Network:** A multimodal driving network constructed using OpenStreetMap (OSM) via the OSMnx Python library.\n",
    "\n",
    "**The Edge Effect Challenge**\n",
    "A common methodological flaw in urban spatial analysis is the \"Edge Effect,\" where facilities immediately outside the city boundaries are ignored. This artificially deflates accessibility scores for border neighborhoods. As shown below, we corrected this by buffering the study area to include facilities in New Jersey and the Pennsylvania suburbs.\n",
    "\"\"\"\n",
    "\n",
    "text_edge_desc = \"\"\"\n",
    "*Figure 1: The \"Edge Effect\" Correction. Red markers indicate facilities outside the city limits (e.g., in Camden, NJ or Lower Merion, PA) that were included in the calculation to ensure accurate scoring for peripheral Philadelphia neighborhoods.*\n",
    "\"\"\"\n",
    "\n",
    "# --- Section 3: Input Variables ---\n",
    "text_inputs = \"\"\"\n",
    "## 2. Input Variables\n",
    "The analysis considers the interaction between demand (Population Density) and sociodemographic risk (Social Vulnerability).\n",
    "\"\"\"\n",
    "\n",
    "# --- Section 4: Results Analysis ---\n",
    "text_results = \"\"\"\n",
    "## 3. Results: The Equity Gap\n",
    "The map below visualizes the **Equity Gap**, defined as the percentage of accessibility lost when a patient is restricted to Medicaid-only facilities.\n",
    "\n",
    "**Key Analytical Findings:**\n",
    "1.  **The Central Paradox:** While Center City possesses the highest density of medical infrastructure, the Medicaid acceptance rate varies. However, the sheer volume of providers buffers this area from becoming a desert.\n",
    "2.  **The North Philadelphia Crisis:** Areas with the highest Social Vulnerability (High SVI) coincides with significant \"Access Loss.\" This suggests that the populations most in need of safety-net care face structural barriers even in urban settings.\n",
    "3.  **Structural Inequality:** The correlation between high SVI and high Equity Gap suggests that the healthcare market is not optimized for public insurance users in specific residential zones.\n",
    "\"\"\"\n",
    "\n",
    "# --- Section 5: Neighborhood Typologies ---\n",
    "text_cluster = \"\"\"\n",
    "## 4. Neighborhood Typologies (Cluster Analysis)\n",
    "To move beyond simple mapping, we performed **K-Means Clustering** to categorize neighborhoods based on the intersection of Accessibility and Vulnerability. This reveals four distinct neighborhood types:\n",
    "\n",
    "1.  **Privileged (Low SVI, High Access):** Neighborhoods with high resources and high healthcare availability.\n",
    "2.  **Supported (High SVI, High Access):** Vulnerable neighborhoods that are well-served by safety-net institutions.\n",
    "3.  **Critical Deserts (High SVI, Low Access):** The highest priority for policy intervention. These residents face high socioeconomic risks and have the lowest physical access to care.\n",
    "4.  **Moderate Access:** Transitional zones.\n",
    "\"\"\"\n",
    "\n",
    "# --- Section 6: Policy Implications & Conclusion ---\n",
    "text_policy = \"\"\"\n",
    "## 5. Policy Implications & Conclusion\n",
    "Based on the \"Weighted Impact\" metric, which combines the Equity Gap with Social Vulnerability, we recommend the following interventions:\n",
    "\n",
    "* **Targeted Expansion:** New Federally Qualified Health Centers (FQHCs) should be prioritized in the \"Critical Desert\" clusters identified in North and Southwest Philadelphia.\n",
    "* **Transportation Subsidies:** For high-gap areas, improving transit connectivity to the existing safety-net hospitals is more cost-effective than building new infrastructure.\n",
    "* **Insurance Incentives:** State-level policy should explore incentives for private hospitals in \"High Gap\" zones to increase their Medicaid intake caps.\n",
    "\n",
    "**Limitations**\n",
    "This study assumes travel by car. Future iterations should incorporate public transit network analysis (GTFS data) to better represent the reality of low-income residents who are less likely to own private vehicles.\n",
    "\"\"\"\n",
    "\n",
    "text_interactive_header = \"\"\"\n",
    "## 6. Interactive Data Explorer\n",
    "Use the dashboard below to toggle between different analytical layers.\n",
    "\"\"\"\n",
    "\n",
    "# =========================================================\n",
    "# 5. DASHBOARD ASSEMBLY\n",
    "# =========================================================\n",
    "print(\"Assembling final dashboard layout...\")\n",
    "\n",
    "# Create the main layout container\n",
    "dashboard = pn.Column(\n",
    "    # --- Header ---\n",
    "    pn.pane.Markdown(text_intro, styles=custom_style),\n",
    "    pn.layout.Divider(),\n",
    "    \n",
    "    # --- Methodology ---\n",
    "    pn.pane.Markdown(text_method, styles=custom_style),\n",
    "    pn.pane.PNG(IMG_EDGE_EFFECT, width=800, align='center'),\n",
    "    pn.pane.Markdown(text_edge_desc, styles={'font-size': '0.9em', 'font-style': 'italic', 'color': '#666', 'text-align': 'center'}),\n",
    "    \n",
    "    # --- Inputs ---\n",
    "    pn.pane.Markdown(text_inputs, styles=custom_style),\n",
    "    pn.Row(\n",
    "        pn.pane.PNG(IMG_POP, width=450),\n",
    "        pn.pane.PNG(IMG_SVI, width=450),\n",
    "        align='center'\n",
    "    ),\n",
    "    \n",
    "    # --- Results ---\n",
    "    pn.layout.Divider(),\n",
    "    pn.pane.Markdown(text_results, styles=custom_style),\n",
    "    pn.pane.PNG(IMG_STATIC_MAP, width=800, align='center'),\n",
    "    \n",
    "    # --- Clustering ---\n",
    "    pn.layout.Divider(),\n",
    "    pn.pane.Markdown(text_cluster, styles=custom_style),\n",
    "    pn.Row(\n",
    "        pn.pane.PNG(IMG_LEGEND, width=400),\n",
    "        pn.pane.PNG(IMG_BOXPLOT, width=500),\n",
    "        align='center'\n",
    "    ),\n",
    "    pn.pane.PNG(IMG_SCATTER, width=800, align='center'),\n",
    "    \n",
    "    # --- Policy & Conclusion ---\n",
    "    pn.layout.Divider(),\n",
    "    pn.pane.Markdown(text_policy, styles=custom_style),\n",
    "    \n",
    "    # --- Interactive Map ---\n",
    "    pn.layout.Divider(),\n",
    "    pn.pane.Markdown(text_interactive_header, styles=custom_style),\n",
    "    interactive_map_pane,\n",
    "    \n",
    "    # --- Footer ---\n",
    "    pn.layout.Divider(),\n",
    "    pn.pane.Markdown(\n",
    "        \"**Data Sources:** OpenDataPhilly, US Census Bureau ACS 2021, CMS Hospital Data. | **Author:** CPLN 6720 Student\", \n",
    "        styles={'text-align': 'center', 'color': 'gray', 'font-size': '0.8em', 'margin-bottom': '50px'}\n",
    "    )\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 6. EXPORT TO HTML\n",
    "# =========================================================\n",
    "# Ensure output directory exists\n",
    "output_dir = Path(\"docs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_file = output_dir / \"index.html\"\n",
    "\n",
    "print(f\"Exporting website to {output_file}...\")\n",
    "\n",
    "# 'embed=True' ensures all images are packed inside the HTML file\n",
    "# 'resources=INLINE' ensures JS libraries are included, making it standalone\n",
    "dashboard.save(str(output_file), embed=True, resources='INLINE')\n",
    "\n",
    "print(\"SUCCESS: The website has been generated in the 'docs' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo310 D)",
   "language": "python",
   "name": "geo310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
